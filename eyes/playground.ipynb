{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.blocks.residuals import ResidualAdd\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block = nn.Identity()\n",
    "        self.shortcut = nn.Identity()\n",
    "        self.res_func = None\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        x = self.block(x)\n",
    "        if self.res_func is not None:\n",
    "            x = self.res_func(x, res)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBasicBlock(Residual):\n",
    "    def __init__(self, in_features, out_features, activation: nn.Module = nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(OrderedDict(\n",
    "            {'conv1': nn.Conv2d(in_features, out_features, kernel_size=3, stride=2),\n",
    "             'bn1': nn.BatchNorm2d(out_features),\n",
    "             'act1': activation,\n",
    "             'conv1': nn.Conv2d(out_features, out_features, kernel_size=3),\n",
    "             'bn1': nn.BatchNorm2d(out_features)}))\n",
    "        \n",
    "        self.shortcut = nn.Sequential(OrderedDict({\n",
    "            'conv': nn.Conv2d(in_features, out_features, kernel_size=1, stride=2, bias=False),\n",
    "            'bn': nn.BatchNorm2d(out_features)\n",
    "        }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNetBasicBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation: nn.Module = nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "        self.in_features, self.out_features = in_features, out_features\n",
    "        self.block = ResidualAdd(\n",
    "            nn.Sequential(OrderedDict(\n",
    "            {'conv1': nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "             'bn1': nn.BatchNorm2d(out_features),\n",
    "             'act1': activation,\n",
    "             'conv2': nn.Conv2d(out_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "             'bn2': nn.BatchNorm2d(out_features),\n",
    "            })),\n",
    "             shortcut=nn.Sequential(OrderedDict({\n",
    "            'conv': nn.Conv2d(in_features, out_features, kernel_size=1, stride=2, bias=False),\n",
    "            'bn': nn.BatchNorm2d(out_features) if self.should_apply_shortcut else None\n",
    "        }))\n",
    "        )\n",
    "        self.act = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_features != self.out_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, block: nn.Module, features: int, reduction=16):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.se = SELayer(features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        x = self.se(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ResNetBasicBlock(32, 64)\n",
    "se_res = SEModule(res, features=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.6738,  ..., 0.0000, 0.3328, 0.0000],\n",
       "          [0.0000, 0.0889, 0.0000,  ..., 0.0000, 0.0000, 0.5379],\n",
       "          [0.0000, 0.1901, 0.3449,  ..., 0.0000, 0.6459, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7397, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.1589,  ..., 0.0000, 0.0000, 0.0182],\n",
       "          [0.0411, 0.5858, 0.0000,  ..., 0.4667, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.7064, 0.0000, 0.0000],\n",
       "          [0.0000, 1.2824, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3845,  ..., 0.4785, 0.4482, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.6119, 1.6757,  ..., 0.0000, 0.0000, 0.3173],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0094, 0.0000, 1.1220],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0109, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.8985, 0.0000,  ..., 0.5922, 0.0000, 0.5688],\n",
       "          [0.1740, 0.7287, 0.0000,  ..., 0.0000, 0.4529, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6724, 0.0000, 0.1823],\n",
       "          ...,\n",
       "          [0.0557, 0.0000, 0.0000,  ..., 0.0444, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4065, 0.0000, 0.8108],\n",
       "          [0.0000, 1.6879, 0.2081,  ..., 0.0000, 0.9768, 0.3009]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3522],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4986, 0.4933],\n",
       "          [0.0000, 0.0473, 0.5073,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.3479,  ..., 0.0000, 0.8055, 0.3999],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5752, 0.5461],\n",
       "          [0.3674, 0.0000, 0.2967,  ..., 0.0000, 0.0000, 0.0065]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.7488, 1.0023],\n",
       "          [0.0000, 0.2940, 0.0000,  ..., 0.6221, 0.0000, 0.1540],\n",
       "          [0.0000, 0.0000, 0.2541,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1585, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2576],\n",
       "          [1.0024, 0.4816, 0.6723,  ..., 0.7796, 0.0000, 0.0000],\n",
       "          [0.0231, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2661]],\n",
       "\n",
       "         [[0.4611, 0.6117, 0.0000,  ..., 0.0000, 0.0000, 0.1588],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.9706, 0.0867,  ..., 0.2592, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [1.1126, 0.3984, 0.5470,  ..., 0.1263, 1.5448, 0.0000],\n",
       "          [0.7975, 0.0000, 0.0000,  ..., 0.2749, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.7364, 0.0000, 0.3905]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_res(torch.rand(1, 32,40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
