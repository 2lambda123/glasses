{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "from functools import partial\n",
    "from glasses.nn.blocks import ConvBnAct, Conv2dPad\n",
    "from glasses.nn.models.segmentation.unet import UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 384, 384])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification import ResNet\n",
    "from glasses.nn.models.segmentation.unet import  UNet\n",
    "\n",
    "resnet34 = ResNet.resnet18()\n",
    "# we need to change the first conv in order to accept a gray image\n",
    "resnet34.encoder.blocks[0].block[0].block.block.conv1 = Conv2dPad(1, 64, kernel_size=1)\n",
    "\n",
    "unet = UNet(1, n_classes=2, blocks_sizes=resnet34.encoder.blocks_sizes)\n",
    "\n",
    "unet.encoder.blocks = resnet34.encoder.blocks\n",
    "\n",
    "x = torch.rand((1, 1, 32 * 12, 32*12))\n",
    "unet(x).shape\n",
    "\n",
    "# unet.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 384, 384])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.senet import SENetBasicBlock\n",
    "\n",
    "block = SENetBasicBlock\n",
    "\n",
    "unet = UNet(down_block=SENetBasicBlock, up_block=SENetBasicBlock)\n",
    "\n",
    "x = torch.rand((1, 1, 32 * 12, 32*12))\n",
    "unet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 384, 384])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet = UNet(n_classes=4)\n",
    "unet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 256, 96, 96]),\n",
       " torch.Size([1, 128, 192, 192]),\n",
       " torch.Size([1, 64, 384, 384])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.shape for r in unet.residuals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.mobilenet import InvertedResidualBlock\n",
    "from glasses.nn.models.classification.se import SEModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpBlock(\n",
       "  (up): ConvTranspose2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (block): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2dPad(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (1): ConvBnAct(\n",
       "        (conv): Conv2dPad(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UpBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
