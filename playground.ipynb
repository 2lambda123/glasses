{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from glasses.nn.models.classification import *\n",
    "from glasses.utils.Storage import ForwardModuleStorage\n",
    "from glasses.nn.models.segmentation.unet import *\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder, ResNet, ResNetBottleneckBlock\n",
    "from glasses.nn.models.classification.efficientnet import *\n",
    "from glasses.nn.models.classification import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 40, 24, 32, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "backbone = EfficientNet.efficientnet_b0().encoder\n",
    "\n",
    "\n",
    "encoder = SegmentationEncoder(backbone, \n",
    "                              stages = [\n",
    "                                  backbone.stem[-2], \n",
    "                                  backbone.layers[1],\n",
    "                                  backbone.layers[2],\n",
    "                                  backbone.layers[3],\n",
    "                              ],\n",
    "                              widths = [32, 24, 40, 80]\n",
    "                             )\n",
    "\n",
    "\n",
    "m = UNet(encoder = lambda *args, **kwargs: encoder, decoder = partial(UNetDecoder, \n",
    "                                                                      widths=[1280, 256, 128, 64, 32, 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              SiLU-3         [-1, 32, 112, 112]               0\n",
      "          Identity-4         [-1, 32, 112, 112]               0\n",
      "         Conv2dPad-5         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
      "              SiLU-7         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-8             [-1, 32, 1, 1]               0\n",
      "            Conv2d-9              [-1, 8, 1, 1]             264\n",
      "             SiLU-10              [-1, 8, 1, 1]               0\n",
      "           Conv2d-11             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-12             [-1, 32, 1, 1]               0\n",
      "        ChannelSE-13         [-1, 32, 112, 112]               0\n",
      "        Conv2dPad-14         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-15         [-1, 16, 112, 112]              32\n",
      "         Identity-16         [-1, 16, 112, 112]               0\n",
      "EfficientNetBasicBlock-17         [-1, 16, 112, 112]               0\n",
      "      ResNetLayer-18         [-1, 16, 112, 112]               0\n",
      "        Conv2dPad-19         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-20         [-1, 96, 112, 112]             192\n",
      "             SiLU-21         [-1, 96, 112, 112]               0\n",
      "        Conv2dPad-22           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-23           [-1, 96, 56, 56]             192\n",
      "             SiLU-24           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-25             [-1, 96, 1, 1]               0\n",
      "           Conv2d-26              [-1, 4, 1, 1]             388\n",
      "             SiLU-27              [-1, 4, 1, 1]               0\n",
      "           Conv2d-28             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-29             [-1, 96, 1, 1]               0\n",
      "        ChannelSE-30           [-1, 96, 56, 56]               0\n",
      "        Conv2dPad-31           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-32           [-1, 24, 56, 56]              48\n",
      "         Identity-33           [-1, 24, 56, 56]               0\n",
      "EfficientNetBasicBlock-34           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-35          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-36          [-1, 144, 56, 56]             288\n",
      "             SiLU-37          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-38          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-39          [-1, 144, 56, 56]             288\n",
      "             SiLU-40          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-41            [-1, 144, 1, 1]               0\n",
      "           Conv2d-42              [-1, 6, 1, 1]             870\n",
      "             SiLU-43              [-1, 6, 1, 1]               0\n",
      "           Conv2d-44            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-45            [-1, 144, 1, 1]               0\n",
      "        ChannelSE-46          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-47           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-48           [-1, 24, 56, 56]              48\n",
      "        Dropout2d-49           [-1, 24, 56, 56]               0\n",
      "EfficientNetBasicBlock-50           [-1, 24, 56, 56]               0\n",
      "      ResNetLayer-51           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-52          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-53          [-1, 144, 56, 56]             288\n",
      "             SiLU-54          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-55          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-56          [-1, 144, 28, 28]             288\n",
      "             SiLU-57          [-1, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-58            [-1, 144, 1, 1]               0\n",
      "           Conv2d-59              [-1, 6, 1, 1]             870\n",
      "             SiLU-60              [-1, 6, 1, 1]               0\n",
      "           Conv2d-61            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-62            [-1, 144, 1, 1]               0\n",
      "        ChannelSE-63          [-1, 144, 28, 28]               0\n",
      "        Conv2dPad-64           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-65           [-1, 40, 28, 28]              80\n",
      "         Identity-66           [-1, 40, 28, 28]               0\n",
      "EfficientNetBasicBlock-67           [-1, 40, 28, 28]               0\n",
      "        Conv2dPad-68          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-69          [-1, 240, 28, 28]             480\n",
      "             SiLU-70          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-71          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-72          [-1, 240, 28, 28]             480\n",
      "             SiLU-73          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-74            [-1, 240, 1, 1]               0\n",
      "           Conv2d-75             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-76             [-1, 10, 1, 1]               0\n",
      "           Conv2d-77            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-78            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-79          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-80           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-81           [-1, 40, 28, 28]              80\n",
      "        Dropout2d-82           [-1, 40, 28, 28]               0\n",
      "EfficientNetBasicBlock-83           [-1, 40, 28, 28]               0\n",
      "      ResNetLayer-84           [-1, 40, 28, 28]               0\n",
      "        Conv2dPad-85          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-86          [-1, 240, 28, 28]             480\n",
      "             SiLU-87          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-88          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-89          [-1, 240, 14, 14]             480\n",
      "             SiLU-90          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-91            [-1, 240, 1, 1]               0\n",
      "           Conv2d-92             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-93             [-1, 10, 1, 1]               0\n",
      "           Conv2d-94            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-95            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-96          [-1, 240, 14, 14]               0\n",
      "        Conv2dPad-97           [-1, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-98           [-1, 80, 14, 14]             160\n",
      "         Identity-99           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-100           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-101          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-102          [-1, 480, 14, 14]             960\n",
      "            SiLU-103          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-104          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-105          [-1, 480, 14, 14]             960\n",
      "            SiLU-106          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-107            [-1, 480, 1, 1]               0\n",
      "          Conv2d-108             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-109             [-1, 20, 1, 1]               0\n",
      "          Conv2d-110            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-111            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-112          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-113           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-114           [-1, 80, 14, 14]             160\n",
      "       Dropout2d-115           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-116           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-117          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-118          [-1, 480, 14, 14]             960\n",
      "            SiLU-119          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-120          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-121          [-1, 480, 14, 14]             960\n",
      "            SiLU-122          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 480, 1, 1]               0\n",
      "          Conv2d-124             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-125             [-1, 20, 1, 1]               0\n",
      "          Conv2d-126            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-127            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-128          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-129           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-130           [-1, 80, 14, 14]             160\n",
      "       Dropout2d-131           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-132           [-1, 80, 14, 14]               0\n",
      "     ResNetLayer-133           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-134          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-135          [-1, 480, 14, 14]             960\n",
      "            SiLU-136          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-137          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-138          [-1, 480, 14, 14]             960\n",
      "            SiLU-139          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-140            [-1, 480, 1, 1]               0\n",
      "          Conv2d-141             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-142             [-1, 20, 1, 1]               0\n",
      "          Conv2d-143            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-144            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-145          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-146          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-147          [-1, 112, 14, 14]             224\n",
      "        Identity-148          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-149          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-150          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-151          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-152          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-153          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-154          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-155          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-156            [-1, 672, 1, 1]               0\n",
      "          Conv2d-157             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-158             [-1, 28, 1, 1]               0\n",
      "          Conv2d-159            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-160            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-161          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-162          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-163          [-1, 112, 14, 14]             224\n",
      "       Dropout2d-164          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-165          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-166          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-167          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-168          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-169          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-170          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-171          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-172            [-1, 672, 1, 1]               0\n",
      "          Conv2d-173             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-174             [-1, 28, 1, 1]               0\n",
      "          Conv2d-175            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-176            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-177          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-178          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-179          [-1, 112, 14, 14]             224\n",
      "       Dropout2d-180          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-181          [-1, 112, 14, 14]               0\n",
      "     ResNetLayer-182          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-183          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-184          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-185          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-186            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-187            [-1, 672, 7, 7]           1,344\n",
      "            SiLU-188            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-189            [-1, 672, 1, 1]               0\n",
      "          Conv2d-190             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-191             [-1, 28, 1, 1]               0\n",
      "          Conv2d-192            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-193            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-194            [-1, 672, 7, 7]               0\n",
      "       Conv2dPad-195            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-196            [-1, 192, 7, 7]             384\n",
      "        Identity-197            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-198            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-199           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-200           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-201           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-202           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-203           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-204           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-205           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-206             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-207             [-1, 48, 1, 1]               0\n",
      "          Conv2d-208           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-209           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-210           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-211            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-212            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-213            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-214            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-215           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-216           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-217           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-218           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-219           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-220           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-221           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-222             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-223             [-1, 48, 1, 1]               0\n",
      "          Conv2d-224           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-225           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-226           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-227            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-228            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-229            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-230            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-231           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-232           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-233           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-234           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-235           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-236           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-237           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-238             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-239             [-1, 48, 1, 1]               0\n",
      "          Conv2d-240           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-241           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-242           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-243            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-244            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-245            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-246            [-1, 192, 7, 7]               0\n",
      "     ResNetLayer-247            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-248           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-249           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-250           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-251           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-252           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-253           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-254           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-255             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-256             [-1, 48, 1, 1]               0\n",
      "          Conv2d-257           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-258           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-259           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-260            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-261            [-1, 320, 7, 7]             640\n",
      "        Identity-262            [-1, 320, 7, 7]               0\n",
      "EfficientNetBasicBlock-263            [-1, 320, 7, 7]               0\n",
      "     ResNetLayer-264            [-1, 320, 7, 7]               0\n",
      "       Conv2dPad-265           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-266           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-267           [-1, 1280, 7, 7]               0\n",
      "EfficientNetEncoder-268           [-1, 1280, 7, 7]               0\n",
      "SegmentationEncoder-269           [-1, 1280, 7, 7]               0\n",
      " ConvTranspose2d-270          [-1, 256, 14, 14]       1,310,976\n",
      "       Conv2dPad-271          [-1, 256, 14, 14]         774,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "         UpLayer-277          [-1, 256, 14, 14]               0\n",
      " ConvTranspose2d-278          [-1, 128, 28, 28]         131,200\n",
      "       Conv2dPad-279          [-1, 128, 28, 28]         193,536\n",
      "     BatchNorm2d-280          [-1, 128, 28, 28]             256\n",
      "            ReLU-281          [-1, 128, 28, 28]               0\n",
      "       Conv2dPad-282          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-283          [-1, 128, 28, 28]             256\n",
      "            ReLU-284          [-1, 128, 28, 28]               0\n",
      "         UpLayer-285          [-1, 128, 28, 28]               0\n",
      " ConvTranspose2d-286           [-1, 64, 56, 56]          32,832\n",
      "       Conv2dPad-287           [-1, 64, 56, 56]          50,688\n",
      "     BatchNorm2d-288           [-1, 64, 56, 56]             128\n",
      "            ReLU-289           [-1, 64, 56, 56]               0\n",
      "       Conv2dPad-290           [-1, 64, 56, 56]          36,864\n",
      "     BatchNorm2d-291           [-1, 64, 56, 56]             128\n",
      "            ReLU-292           [-1, 64, 56, 56]               0\n",
      "         UpLayer-293           [-1, 64, 56, 56]               0\n",
      " ConvTranspose2d-294         [-1, 32, 112, 112]           8,224\n",
      "       Conv2dPad-295         [-1, 32, 112, 112]          18,432\n",
      "     BatchNorm2d-296         [-1, 32, 112, 112]              64\n",
      "            ReLU-297         [-1, 32, 112, 112]               0\n",
      "       Conv2dPad-298         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-299         [-1, 32, 112, 112]              64\n",
      "            ReLU-300         [-1, 32, 112, 112]               0\n",
      "         UpLayer-301         [-1, 32, 112, 112]               0\n",
      " ConvTranspose2d-302         [-1, 16, 224, 224]           2,064\n",
      "       Conv2dPad-303         [-1, 16, 224, 224]           2,304\n",
      "     BatchNorm2d-304         [-1, 16, 224, 224]              32\n",
      "            ReLU-305         [-1, 16, 224, 224]               0\n",
      "       Conv2dPad-306         [-1, 16, 224, 224]           2,304\n",
      "     BatchNorm2d-307         [-1, 16, 224, 224]              32\n",
      "            ReLU-308         [-1, 16, 224, 224]               0\n",
      "         UpLayer-309         [-1, 16, 224, 224]               0\n",
      "          Conv2d-310          [-1, 2, 224, 224]              34\n",
      "            UNet-311          [-1, 2, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 7,319,630\n",
      "Trainable params: 7,319,630\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 279.76\n",
      "Params size (MB): 27.92\n",
      "Estimated Total Size (MB): 308.26\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(7319630), tensor(7319630), tensor(27.9222), tensor(308.2561))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 32, 112, 112]),\n",
       " torch.Size([1, 24, 56, 56]),\n",
       " torch.Size([1, 40, 28, 28]),\n",
       " torch.Size([1, 80, 14, 14])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = encoder(torch.randn(1,3,224,224))\n",
    "\n",
    "[ f.shape for f in encoder.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "backbone = EfficientNet.efficientnet_b0()\n",
    "# backbone =ResNet.resnet18()\n",
    "\n",
    "encoder = SegmentationEncoder(backbone.encoder, \n",
    "                              [backbone.encoder.stem[-2], *backbone.encoder.layers],\n",
    "                             )\n",
    "\n",
    "\n",
    "m = UNet(encoder = lambda *args, **kwargs: encoder, decoder = partial(UNetDecoder, \n",
    "                                                                      widths=[512, 256, 128, 64, 32, 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class SegmentationEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone(*args, **kwargs)\n",
    "\n",
    "        self.storage = ForwardModuleStorage(self.backbone, self.backbone.stages())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    @property\n",
    "    def features(self):\n",
    "        return list(self.storage.state.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = SegmentationEncoder(lambda : ResNet.resnet18(in_channels=1).encoder)\n",
    "x = torch.randn(8,1,224,224)\n",
    "\n",
    "encoder(x)\n",
    "\n",
    "print([f.shape for f in encoder.features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = UNet()\n",
    "m.summary((1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet('resnet34')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "summary(model.cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ResNet.resnet26d(in_channels=3).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ResNet.resnet26(in_channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.efficientnet import *\n",
    "import timm\n",
    "\n",
    "from transfer_weights import clone_model\n",
    "from benchmark import benchmark\n",
    "\n",
    "src = timm.create_model('tf_efficientnet_lite1', pretrained='True')\n",
    "dst = EfficientNetLite.efficientnet_lite1(mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = clone_model(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# transform = dst.configs['efficientnet_lite1'].transform\n",
    "\n",
    "# benchmark(dst.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# benchmark(src.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = timm.create_model('efficientnet_b0', pretrained='True')\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
