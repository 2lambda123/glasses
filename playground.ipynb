{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvertedResidualBlock(\n",
       "  (block): Sequential(\n",
       "    (exp): ConvBnAct(\n",
       "      (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU6()\n",
       "    )\n",
       "    (conv): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): DeepthWiseConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (1): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.mobilenet import MobileNetBasicBlock,MobileNetEncoder\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder\n",
    "\n",
    "\n",
    "MobileNetBasicBlock(16, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (encoder): MobileNetEncoder(\n",
       "    (gate): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2dPad(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                    (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                    (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                    (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                    (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                    (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (conv): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                    (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    (act): ReLU6()\n",
       "                  )\n",
       "                  (1): Conv2dPad(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Sequential(\n",
       "              (exp): ConvBnAct(\n",
       "                (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (conv): Sequential(\n",
       "                (0): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (1): Conv2dPad(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2dPad(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ResnetDecoder(\n",
       "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.mobilenet import MobileNetV2\n",
    "\n",
    "\n",
    "MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.mobilenet import InvertedResidualBlock\n",
    "from glasses.nn.models.classification.se import SEModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1891e-02, -3.3119e-02, -6.9089e-02,  5.8009e-02,  2.2558e-01,\n",
       "          4.2044e-03, -2.6955e-02, -3.5164e-02,  1.1589e-01, -1.7936e-01,\n",
       "          1.5273e-02, -4.5371e-02, -1.3467e-01,  1.5656e-01, -1.5472e-01,\n",
       "         -1.5289e-01,  7.5923e-03, -4.5301e-02, -5.1758e-02, -1.8759e-02,\n",
       "         -1.5052e-01,  9.8710e-02,  1.5377e-01, -9.8400e-02,  5.3472e-02,\n",
       "         -1.6462e-01, -1.6329e-01,  8.2865e-02,  2.2678e-02, -1.2449e-01,\n",
       "         -6.2394e-02,  1.3635e-01, -1.1748e-02,  1.2339e-01, -1.5009e-01,\n",
       "          1.1991e-01, -3.2629e-01, -1.3063e-01, -9.4450e-02, -1.6640e-01,\n",
       "         -1.7850e-01, -3.4638e-02,  1.2058e-01, -6.5375e-03, -1.1133e-01,\n",
       "         -5.4890e-02,  1.9763e-01, -2.1211e-01, -1.1976e-01,  7.3937e-02,\n",
       "          6.0420e-02,  1.8373e-02,  2.0716e-01,  8.1907e-02,  2.9820e-01,\n",
       "          1.3336e-01,  4.3899e-02, -1.0331e-01, -7.5655e-02, -2.6063e-02,\n",
       "         -1.5060e-01, -7.8079e-02,  8.5316e-02, -2.3363e-02,  2.5012e-01,\n",
       "          1.8516e-01, -4.1455e-02,  2.9435e-02, -4.5694e-02,  1.6859e-01,\n",
       "          6.6283e-02, -1.3065e-01, -2.9181e-01,  4.4300e-02,  1.6096e-01,\n",
       "         -9.1413e-03, -6.7254e-02, -1.1332e-01,  1.9094e-01,  1.1172e-01,\n",
       "         -1.5645e-01, -2.1774e-02, -1.8518e-01,  1.4828e-01,  1.0280e-02,\n",
       "          1.0361e-01,  2.5227e-01,  1.7305e-01, -8.1246e-03, -2.0846e-01,\n",
       "         -2.1421e-03,  4.4556e-02,  9.1264e-02,  3.0486e-01, -6.4661e-02,\n",
       "          3.3083e-02, -1.2606e-01, -1.4275e-01, -2.3270e-01, -2.9205e-02,\n",
       "          5.5092e-02,  3.4743e-01, -3.0125e-01,  1.2126e-01, -3.3792e-02,\n",
       "          1.0809e-01, -1.6624e-01,  9.1820e-02, -3.1037e-01,  3.6773e-02,\n",
       "          7.0323e-02,  1.8722e-01, -2.4128e-01,  9.2067e-02, -2.0039e-01,\n",
       "         -2.9231e-02, -1.7853e-01,  9.7543e-02,  1.4216e-01, -1.3498e-01,\n",
       "          1.5627e-01, -7.8919e-02, -4.0977e-02,  1.5909e-02,  1.2647e-01,\n",
       "         -2.4588e-01, -2.0514e-01,  1.7387e-01, -2.0379e-01, -5.3912e-02,\n",
       "         -1.1316e-01, -1.3285e-01,  1.5639e-01,  2.0377e-01, -5.3006e-02,\n",
       "          2.1860e-03, -2.1569e-01, -5.6549e-02, -2.3178e-03, -5.0378e-02,\n",
       "         -1.6593e-01, -1.6001e-01,  7.0880e-02,  1.3827e-01, -1.4643e-01,\n",
       "          7.1623e-02, -1.6554e-02,  1.3760e-01, -1.3181e-01,  2.8250e-02,\n",
       "         -2.3431e-02,  1.6528e-01,  2.0787e-01,  7.9980e-03,  8.7371e-02,\n",
       "          1.7092e-01,  6.3991e-02, -2.6749e-01,  1.0659e-01,  2.3881e-01,\n",
       "         -1.4684e-01,  1.8659e-01,  8.5319e-02, -1.2438e-01,  8.9847e-02,\n",
       "         -8.7839e-02,  1.5741e-01,  7.5659e-02,  7.9760e-02,  8.8035e-02,\n",
       "          4.0213e-02,  2.9336e-02, -1.9367e-02, -1.3305e-01, -1.7854e-02,\n",
       "         -1.0319e-01, -2.5377e-01,  1.5456e-01, -9.9921e-02,  3.1231e-01,\n",
       "         -1.8590e-01, -8.2380e-02, -1.4150e-01, -2.0601e-02, -1.5744e-01,\n",
       "         -6.9940e-02,  5.8823e-02,  1.7989e-02,  2.2747e-03, -2.1267e-02,\n",
       "          1.2451e-01,  1.0722e-01, -9.2574e-03, -9.9649e-02,  9.2355e-02,\n",
       "         -1.4814e-01,  1.7185e-01, -4.1819e-02, -6.8216e-02,  1.6742e-01,\n",
       "         -7.0141e-02, -1.2724e-01, -3.4500e-01,  1.2819e-01,  1.5722e-01,\n",
       "          2.7894e-01,  1.0093e-01,  2.0583e-01,  2.9277e-02, -2.2650e-02,\n",
       "         -6.0066e-02,  2.4761e-01,  2.2155e-01, -2.5810e-01,  2.9208e-03,\n",
       "         -8.4517e-02, -1.5941e-01,  3.5290e-01, -1.4671e-01,  2.2117e-01,\n",
       "          2.7737e-01, -1.7564e-01,  2.3771e-01,  1.6204e-02, -1.1009e-01,\n",
       "          8.0227e-02, -7.7905e-02,  1.1979e-01,  1.3206e-01, -9.9364e-02,\n",
       "         -7.0398e-02,  2.1348e-02,  1.6117e-01, -2.2013e-01,  3.2349e-01,\n",
       "          2.3917e-02,  1.3645e-01, -2.4947e-01, -1.3352e-01,  2.0046e-01,\n",
       "          2.6043e-01, -2.2166e-01, -4.7528e-02,  4.8425e-01,  1.0648e-01,\n",
       "          1.6810e-01, -4.4367e-02,  6.6360e-02, -1.0199e-01, -1.2581e-01,\n",
       "          1.9462e-01, -1.8523e-01,  5.8139e-02, -2.0001e-01,  2.9928e-02,\n",
       "         -2.5590e-02,  1.1846e-01,  5.7727e-02,  1.8721e-01, -9.4010e-02,\n",
       "         -1.0297e-01, -6.1199e-02,  5.1088e-02, -8.3752e-02, -8.0811e-02,\n",
       "         -1.6842e-01, -1.3244e-01,  6.8899e-02,  4.0189e-02,  5.6686e-02,\n",
       "         -6.1820e-02, -2.4817e-01,  2.6705e-01, -2.1562e-01,  1.5419e-01,\n",
       "         -1.4959e-02,  2.4200e-01, -1.0812e-01,  1.9669e-01, -1.9502e-02,\n",
       "          4.4538e-02,  2.3379e-02, -6.0007e-02,  1.4263e-01,  7.1264e-02,\n",
       "          1.7906e-01,  9.8777e-02, -2.0321e-02,  4.8756e-03,  2.5871e-01,\n",
       "          1.1481e-01,  1.3908e-01, -2.0689e-01, -9.0843e-02,  6.5292e-03,\n",
       "         -1.4134e-01, -2.3500e-01, -1.0276e-01,  9.6065e-02, -3.0689e-01,\n",
       "         -9.9772e-02,  1.1900e-01, -9.1321e-02, -6.0447e-02,  1.2153e-01,\n",
       "         -5.9607e-02, -7.8129e-02, -1.2280e-01, -9.5345e-02, -1.9626e-04,\n",
       "          1.1191e-01,  8.9229e-02,  1.2778e-01, -2.0454e-01,  1.6154e-01,\n",
       "          4.9393e-02,  5.1629e-02, -1.6531e-01,  6.6142e-02, -2.0608e-02,\n",
       "         -8.2979e-02,  1.1048e-01,  1.9821e-01, -2.4486e-01,  1.9386e-01,\n",
       "          1.0400e-01,  1.1585e-02, -1.0412e-01, -6.6867e-02, -8.7573e-02,\n",
       "         -2.6029e-01, -5.8108e-02,  1.8407e-01, -3.2325e-02,  3.0407e-01,\n",
       "          1.3938e-02,  6.0930e-02, -3.8409e-02, -6.3819e-02,  1.8223e-01,\n",
       "          1.8445e-01, -6.2726e-02,  9.1668e-02, -1.6115e-01, -1.4435e-01,\n",
       "          6.0700e-02,  2.4140e-01, -4.0963e-02, -1.8244e-01, -5.7063e-02,\n",
       "         -1.7086e-01,  1.2316e-01, -1.5516e-01, -1.1583e-02,  3.1381e-01,\n",
       "         -1.9004e-02,  1.8160e-01,  2.0992e-02,  2.1127e-01, -1.6255e-01,\n",
       "         -4.1356e-02, -6.2507e-03, -8.7678e-02, -2.2974e-01,  2.1158e-02,\n",
       "         -1.7768e-01, -2.9346e-01, -3.6257e-01, -1.0863e-02, -8.7780e-03,\n",
       "         -1.5588e-01,  1.1557e-01,  2.0232e-02,  6.9739e-02, -2.7610e-01,\n",
       "          9.4854e-02,  2.0765e-02, -3.8567e-02,  8.2180e-02,  1.4939e-01,\n",
       "         -7.9003e-02, -8.9334e-02,  3.8989e-02, -1.0006e-01,  2.2593e-01,\n",
       "          2.2111e-02, -2.9192e-02, -1.0522e-01,  2.6460e-01,  1.3231e-02,\n",
       "          1.0593e-01,  3.3215e-02,  2.5107e-01, -2.3161e-01,  2.6543e-02,\n",
       "         -3.7553e-02,  3.3079e-01, -1.1444e-01,  1.3719e-01, -1.6639e-03,\n",
       "          9.8821e-02, -2.0064e-01,  2.0038e-01, -1.0493e-01,  2.7598e-01,\n",
       "         -1.2706e-01,  2.1804e-01, -1.3237e-01,  9.9714e-02, -2.2818e-02,\n",
       "          1.3346e-01,  3.8701e-03,  1.1589e-01,  6.8194e-02, -2.9865e-01,\n",
       "         -1.1739e-01, -2.6143e-02, -2.6726e-01,  1.1855e-01, -5.9067e-02,\n",
       "          4.0705e-02,  1.1928e-01, -1.1869e-01,  3.7743e-02,  6.1844e-03,\n",
       "         -6.9966e-02, -1.6925e-01,  2.8325e-02,  2.4983e-01, -1.0259e-01,\n",
       "         -1.0174e-01,  1.7550e-01,  2.7782e-01, -9.7395e-02, -1.8268e-01,\n",
       "          6.9166e-02,  5.9830e-02,  2.4034e-01, -1.5904e-01,  1.1604e-01,\n",
       "          1.9210e-02, -1.6532e-01, -8.0906e-02, -8.9968e-02,  4.9317e-02,\n",
       "         -1.5660e-01,  1.7020e-01,  2.4807e-02,  2.5227e-02, -7.6035e-02,\n",
       "          3.3741e-02,  4.9841e-02, -2.8090e-01,  1.1425e-01, -1.5297e-01,\n",
       "          1.0951e-01, -1.6281e-01,  7.8952e-02, -1.3715e-01,  2.7921e-02,\n",
       "         -5.6379e-02, -2.7722e-01, -3.8570e-01, -5.1588e-02, -2.1405e-02,\n",
       "          1.4770e-03, -1.6297e-01, -4.5820e-02, -3.7766e-02,  1.4359e-01,\n",
       "          9.3611e-03,  2.1367e-02, -1.4170e-01, -1.8713e-02, -7.0826e-02,\n",
       "         -4.1015e-02, -6.7407e-02, -5.4516e-02,  1.1955e-02, -2.0612e-01,\n",
       "          3.0956e-01,  6.2203e-02, -1.9436e-01, -1.7429e-01,  3.3941e-02,\n",
       "          1.3936e-01, -1.6022e-01,  1.1843e-01,  1.4668e-01, -9.4267e-03,\n",
       "          9.7654e-02, -8.4313e-02, -1.2519e-01,  2.6325e-01, -1.9286e-01,\n",
       "         -5.3331e-02,  9.2167e-02, -2.3474e-01,  1.4839e-01,  3.0701e-01,\n",
       "          8.6932e-02,  7.5406e-02, -1.6439e-02, -1.2650e-01,  8.1263e-02,\n",
       "          7.8893e-03,  5.2433e-03,  2.8481e-01,  6.1395e-02,  2.3579e-02,\n",
       "          3.3501e-02,  4.0888e-02, -1.1941e-03, -5.1159e-02, -1.3882e-01,\n",
       "         -3.8495e-02, -1.4785e-01,  7.2192e-03,  7.2704e-02,  2.6469e-03,\n",
       "         -7.9969e-02, -1.9833e-02,  3.0350e-02, -1.2916e-01, -1.0483e-01,\n",
       "          1.0166e-01,  1.3784e-01,  2.7949e-01, -3.2364e-03,  3.6241e-01,\n",
       "         -3.8379e-01, -5.6958e-03,  9.0258e-02,  3.6665e-02, -2.1547e-01,\n",
       "         -3.3297e-02,  1.0474e-01, -1.4936e-02, -1.6310e-01,  3.7659e-02,\n",
       "         -3.6182e-01, -1.6827e-01, -1.6377e-01, -7.9065e-02, -7.3617e-02,\n",
       "          9.6562e-02, -2.0950e-01,  2.7694e-02, -6.0240e-02, -2.3501e-01,\n",
       "         -1.3068e-01,  2.7939e-02, -7.7993e-02, -2.7699e-01,  1.1110e-01,\n",
       "          4.3274e-01,  6.9561e-02, -6.9909e-02, -4.0783e-02,  2.0225e-01,\n",
       "          8.2104e-02,  1.4696e-01, -1.3709e-01, -2.5093e-01, -1.9581e-01,\n",
       "         -1.3753e-01, -1.4076e-01, -1.7664e-01, -5.8985e-04,  9.4775e-02,\n",
       "          8.2094e-02, -1.3906e-01, -1.8510e-02,  1.4721e-01,  2.0582e-01,\n",
       "          1.1056e-01, -5.8651e-02, -9.0425e-02, -9.1614e-02,  2.3323e-02,\n",
       "         -3.5514e-02, -1.3715e-01,  1.1318e-01, -1.2347e-02, -2.7924e-01,\n",
       "          6.5428e-02,  1.7598e-01,  9.3976e-02,  4.4178e-01, -2.2737e-01,\n",
       "          6.3854e-02,  2.3184e-02,  2.9572e-01,  6.3863e-02,  4.7091e-03,\n",
       "          1.1868e-01,  1.3030e-01, -1.4261e-01,  4.6898e-02, -2.0060e-01,\n",
       "         -9.2328e-02, -6.2486e-03,  3.2760e-04, -1.0096e-01, -1.0900e-01,\n",
       "         -5.1646e-02,  1.1678e-01, -4.6591e-03, -1.5629e-01, -1.0961e-01,\n",
       "         -8.9616e-02,  1.5800e-02, -2.6257e-01,  2.5435e-01,  3.2237e-02,\n",
       "          3.3717e-03,  9.0502e-02,  1.7544e-01, -6.1230e-02,  7.4957e-02,\n",
       "         -9.3953e-02, -1.0805e-01,  7.7751e-02, -1.9723e-02, -1.8878e-01,\n",
       "         -2.1696e-02, -3.1964e-02,  1.7096e-01,  1.9889e-01, -1.1613e-01,\n",
       "          1.3674e-01, -2.6664e-03, -5.9003e-02, -3.1671e-02,  1.2832e-01,\n",
       "          7.9104e-03, -7.4151e-02,  1.1289e-01, -1.2649e-01,  2.7637e-02,\n",
       "         -2.6073e-01, -3.1838e-01, -1.5087e-01, -1.2653e-01, -1.5863e-01,\n",
       "          3.8222e-02, -2.7825e-01,  6.4567e-02,  2.0948e-01,  1.7805e-01,\n",
       "          4.6458e-02, -1.8882e-01,  1.8705e-01,  1.3780e-01,  1.1468e-01,\n",
       "          3.1182e-02, -2.0263e-01,  3.5869e-02, -4.5811e-03,  1.7921e-01,\n",
       "         -9.9715e-02,  7.9402e-02,  7.0530e-02,  1.5640e-02, -3.9161e-01,\n",
       "          4.0737e-02, -9.7010e-02,  1.4504e-03, -2.3565e-01,  1.2536e-01,\n",
       "          2.8438e-02, -1.9030e-01,  9.1113e-02,  7.0434e-02, -1.3016e-01,\n",
       "         -9.1181e-02,  5.1247e-02, -7.2759e-02, -2.6245e-01,  1.8338e-01,\n",
       "         -3.0390e-01,  8.5014e-02, -2.8845e-01, -5.3220e-02,  4.0545e-02,\n",
       "         -1.8877e-01, -1.1140e-01, -7.3329e-02,  2.6989e-02,  1.0274e-01,\n",
       "         -5.8750e-02, -1.3970e-01, -1.0986e-02, -2.1510e-01,  1.4630e-01,\n",
       "         -1.4298e-01, -3.5837e-02,  1.3288e-02,  1.0066e-01,  2.4613e-02,\n",
       "         -6.1847e-02, -1.7727e-01,  1.0993e-01,  3.2935e-01,  2.8353e-02,\n",
       "         -1.5372e-01,  7.4078e-02, -8.6086e-03,  2.7530e-01, -1.1549e-01,\n",
       "          2.5202e-01,  9.8850e-02,  9.7008e-02, -7.0291e-02,  3.0874e-02,\n",
       "         -1.0520e-01, -1.8164e-01,  1.2536e-01,  1.5378e-01, -1.8039e-02,\n",
       "         -1.0042e-02,  7.3274e-02,  8.3758e-02,  1.4705e-02, -3.9267e-02,\n",
       "         -7.5815e-02, -4.4317e-02, -9.7852e-02, -2.4112e-01, -5.2499e-02,\n",
       "          3.2826e-01, -4.5939e-02, -6.1094e-02, -9.7356e-02, -1.6384e-01,\n",
       "         -3.0086e-02, -4.9954e-02,  7.8246e-02,  1.3949e-01,  3.7729e-02,\n",
       "          5.7017e-02,  6.7700e-02, -9.4519e-02,  1.9924e-02, -1.9898e-01,\n",
       "          9.1836e-02,  8.7697e-03,  1.1350e-01,  7.4452e-02,  6.2396e-02,\n",
       "         -2.2467e-01,  3.6784e-02, -1.8487e-01, -2.0730e-01, -3.4870e-02,\n",
       "          1.9037e-01, -2.8230e-01, -6.2229e-02,  7.2340e-02,  8.1360e-02,\n",
       "          5.5209e-02,  1.0520e-01, -3.1521e-01,  6.7290e-02,  1.2453e-01,\n",
       "          5.2718e-02, -1.0360e-01,  7.2662e-03, -1.7722e-01, -2.2092e-01,\n",
       "          1.1552e-02,  4.9752e-02, -8.2549e-02,  1.2448e-01, -1.8034e-02,\n",
       "          1.8593e-01,  4.4542e-02,  2.8097e-01,  7.5813e-02,  3.4616e-02,\n",
       "         -4.1700e-02, -7.6942e-02,  6.2273e-02, -1.2021e-01, -9.5893e-02,\n",
       "         -1.5216e-01,  3.7698e-02,  9.2762e-02,  6.5397e-02,  8.1391e-02,\n",
       "         -8.1925e-02,  3.2591e-01,  1.5805e-01,  3.0038e-01, -1.0021e-01,\n",
       "         -1.0927e-01, -3.2014e-01, -1.5779e-01, -1.3959e-01, -4.2957e-02,\n",
       "          3.2075e-02, -4.4062e-03, -1.5642e-01, -9.6929e-02, -1.5258e-01,\n",
       "         -1.2622e-01, -1.7014e-01,  5.2913e-02,  1.4242e-01,  7.7561e-02,\n",
       "          4.4982e-02,  2.1007e-01, -9.0827e-02, -2.9897e-02, -3.0691e-02,\n",
       "          2.6655e-01, -1.7196e-02, -1.5534e-01, -1.7450e-01,  3.3345e-03,\n",
       "         -9.4738e-02,  1.9574e-01,  2.1614e-01, -1.6934e-01, -9.9123e-02,\n",
       "         -5.1999e-03, -1.0544e-01, -1.1527e-01, -1.9313e-01, -1.4235e-01,\n",
       "          7.9231e-04,  2.8886e-01, -2.2911e-01,  1.2505e-01, -1.0919e-02,\n",
       "         -2.8499e-01,  5.5402e-02, -1.6324e-01,  3.3271e-02,  1.9913e-01,\n",
       "         -2.4714e-01,  2.1783e-01, -1.9395e-01,  1.2231e-02, -1.0071e-02,\n",
       "          8.2594e-02, -1.3132e-02,  7.6386e-02,  1.3215e-01,  9.9017e-02,\n",
       "         -2.8064e-01, -7.2190e-02,  1.1516e-02, -1.1913e-01, -1.3131e-01,\n",
       "         -3.1748e-01, -3.7569e-02,  1.1322e-01,  4.6117e-02,  1.1449e-01,\n",
       "         -2.4444e-01, -3.0494e-02,  3.1100e-02, -2.0680e-01, -4.0696e-03,\n",
       "          2.2332e-02,  1.8391e-02,  5.4084e-02,  1.1027e-01,  1.7768e-01,\n",
       "          3.2789e-02,  2.3574e-01, -1.0088e-01, -2.0147e-01,  1.4781e-01,\n",
       "          1.1213e-02,  2.7479e-04, -9.3335e-03, -2.4062e-01,  1.0983e-01,\n",
       "         -1.1332e-01, -5.1475e-02, -8.2515e-02,  3.8525e-02, -6.9761e-02,\n",
       "         -1.9329e-01,  1.6916e-01,  1.1625e-01,  3.9570e-03,  2.6938e-01,\n",
       "         -2.1754e-01, -4.5633e-02,  8.7713e-02, -4.4544e-02,  1.3837e-02,\n",
       "         -9.0094e-02, -1.1227e-01, -1.5053e-01, -5.5386e-03,  1.0398e-01,\n",
       "          1.5606e-01,  1.3491e-01, -4.2163e-02,  1.1725e-01,  1.7263e-01,\n",
       "          1.7502e-01, -1.1902e-02, -9.5789e-02,  5.4884e-03, -1.2665e-01,\n",
       "         -2.8203e-01, -1.0541e-01, -7.4768e-03,  2.3284e-01, -8.0524e-02,\n",
       "         -8.9017e-02,  1.2591e-01,  5.4569e-02, -8.5059e-02, -1.7775e-01,\n",
       "         -1.2576e-01, -1.3021e-01,  1.1219e-02,  7.8527e-02, -2.1028e-01,\n",
       "         -8.9860e-03,  2.4033e-01,  8.4267e-02,  8.1274e-02, -5.2962e-02,\n",
       "          2.5983e-01,  3.2147e-01,  1.8415e-01, -7.0507e-02, -1.7697e-03,\n",
       "          1.9359e-01, -6.1808e-02, -1.3328e-01,  2.1208e-01,  1.2868e-01,\n",
       "         -1.3645e-01, -1.2030e-01,  2.6945e-01, -6.2814e-02, -1.5322e-01,\n",
       "          1.5221e-02, -1.4310e-01, -1.4473e-01, -1.8135e-01,  1.8684e-02,\n",
       "          1.7371e-01, -2.3144e-01,  8.2372e-02,  2.4959e-01,  2.7128e-01,\n",
       "         -6.9217e-02, -6.4195e-02,  1.3130e-01,  1.7225e-01, -5.6986e-02,\n",
       "          1.1712e-01, -1.7044e-02, -3.9778e-02,  2.3398e-01,  1.5455e-01,\n",
       "         -2.2914e-01, -8.5620e-02,  1.8542e-01,  6.6933e-02, -1.4698e-01,\n",
       "          2.6179e-01,  2.9991e-02, -2.6254e-01, -1.3763e-01,  1.5963e-01,\n",
       "          1.5677e-01, -8.1040e-02,  1.5333e-01, -1.2105e-01,  2.1579e-01,\n",
       "          6.0184e-02, -9.4134e-03, -8.6802e-02,  2.6711e-01, -6.7086e-02,\n",
       "         -9.1812e-03,  1.8762e-03,  1.7781e-01, -6.1408e-02, -2.9789e-01,\n",
       "          2.0120e-01, -1.3120e-01, -3.3808e-02, -2.0708e-01,  2.6645e-01,\n",
       "          1.7123e-01, -2.3571e-01, -1.5125e-01, -1.0227e-01, -1.3072e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SEInvertedResidualBlock(InvertedResidualBlock):\n",
    "    def __init__(self, in_features, out_features, *args, **kwargs):\n",
    "        super().__init__(in_features, out_features, *args, **kwargs)\n",
    "        self.block.add_module('se', SEModule(out_features))\n",
    "        \n",
    "        \n",
    "model = MobileNetV2(block=SEInvertedResidualBlock)\n",
    "\n",
    "# SEInvertedResidualBlock(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 16, 112, 112]), torch.Size([1, 24, 56, 56]), torch.Size([1, 32, 28, 28]), torch.Size([1, 64, 14, 14]), torch.Size([1, 96, 14, 14]), torch.Size([1, 160, 7, 7]), torch.Size([1, 320, 7, 7]), torch.Size([1, 1280, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "MobileNetV2(activation = nn.SELU)\n",
    "# change number of classes (default is 1000 )\n",
    "MobileNetV2(n_classes=100)\n",
    "# pass a different block\n",
    "class SEInvertedResidualBlock(InvertedResidualBlock):\n",
    "    def __init__(self, in_features, out_features, *args, **kwargs):\n",
    "        super().__init__(in_features, out_features, *args, **kwargs)\n",
    "        self.block.add_module('se', SEModule(out_features))\n",
    "# now mobile net has squeeze and excitation!\n",
    "MobileNetV2(block=SEInvertedResidualBlock)\n",
    "# change the initial convolution\n",
    "model = MobileNetV2()\n",
    "model.encoder.gate[0].conv = nn.Conv2d(3, 32, kernel_size=7)\n",
    "# store each feature\n",
    "x = torch.rand((1, 3, 224, 224))\n",
    "model =MobileNetV2()\n",
    "features = []\n",
    "x = model.encoder.gate(x)\n",
    "for block in model.encoder.blocks:\n",
    "    x = block(x)\n",
    "    features.append(x)\n",
    "print([x.shape for x in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepthWiseConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, groups=out_channels, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 166.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model_original = mobilenet_v2()\n",
    "\n",
    "summary(model_original.cuda(), (3, 224, 224))\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.utils.ModuleTransfer import ModuleTransfer\n",
    "\n",
    "transfer = ModuleTransfer(model.cpu(), model_original.cpu())\n",
    "\n",
    "transfer(torch.rand((1, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Add Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 res_func: Callable[[Tensor], Tensor] = None,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "        self.res_func = res_func\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        if self.res_func is not None:\n",
    "            x = self.res_func(x, res)\n",
    "        return x\n",
    "\n",
    "\n",
    "def add(x: Tensor, res: Tensor) -> Tensor:\n",
    "    return x.add_(res)\n",
    "\n",
    "\n",
    "ResidualAdd = partial(Residual, res_func=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.3 ms ± 6.57 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        x += res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.7 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (gate): Sequential(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ResnetDecoder(\n",
       "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.utils.PretrainedWeightsProvider import PretrainedWeightsProvider\n",
    "\n",
    "# test if the weights are correct, only for resnet18 \n",
    "PretrainedWeightsProvider()['resnet18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-977f1222c54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNetBasicBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 }\n\u001b[1;32m     68\u001b[0m             )), shortcut=ResNetShorcut(\n\u001b[0;32m---> 69\u001b[0;31m             in_features, out_features * self.expansion, downsampling) if in_features != out_features * self.expansion else None)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/blocks/residuals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, shortcut, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     def __init__(self, block: nn.Module,\n\u001b[1;32m     62\u001b[0m                  shortcut: nn.Module = None, *args, **kwargs):\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "\n",
    "ResNetBasicBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of glasses.nn.models.classification.resnet failed: Traceback (most recent call last):\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: forward() requires a code object with 1 free vars, not 0\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8543bc12316a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(cls, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFrancescoSaverioZuppichini\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglasses\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdevelop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0m_static\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mResNet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mresnet18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, n_classes, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0min_channels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mRGB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mGray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, blocks_sizes, depths, activation, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         self.blocks = nn.ModuleList([\n\u001b[1;32m    227\u001b[0m             ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=depths[0], activation=activation,\n\u001b[0;32m--> 228\u001b[0;31m                         block=block,  *args, **kwargs),\n\u001b[0m\u001b[1;32m    229\u001b[0m             *[ResNetLayer(in_channels * block.expansion,\n\u001b[1;32m    230\u001b[0m                           \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, block, n, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         self.block = nn.Sequential(\n\u001b[1;32m    190\u001b[0m             block(in_channels, out_channels, *args,\n\u001b[0;32m--> 191\u001b[0;31m                   downsampling=downsampling,  **kwargs),\n\u001b[0m\u001b[1;32m    192\u001b[0m             *[block(out_channels * block.expansion,\n\u001b[1;32m    193\u001b[0m                     out_channels, *args, **kwargs) for _ in range(n - 1)]\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mactivation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLUInPlace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification import ResNet\n",
    "\n",
    "\n",
    "ResNet.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (block): Residual(\n",
      "    (block): Sequential(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (shortcut): ResNetShorcut(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (act): ReLU(inplace=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3507, 0.0000, 0.2612,  ..., 0.0000, 0.0000, 1.0867],\n",
       "          [0.0000, 0.9422, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.2224, 0.2569],\n",
       "          ...,\n",
       "          [0.4459, 0.3775, 3.1123,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.2234,  ..., 1.2519, 0.0000, 0.7491],\n",
       "          [0.0000, 0.0000, 0.3720,  ..., 0.0000, 0.8578, 0.0000]],\n",
       "\n",
       "         [[0.4809, 0.6557, 2.3329,  ..., 0.0000, 0.0000, 0.7809],\n",
       "          [0.0000, 0.8320, 0.0000,  ..., 0.1316, 1.9552, 0.2474],\n",
       "          [0.0000, 0.7629, 0.2113,  ..., 0.0000, 0.0000, 0.3037],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 2.3773,  ..., 0.0000, 0.0000, 0.6268],\n",
       "          [0.0000, 0.0000, 0.8727,  ..., 1.7412, 0.0000, 0.2877],\n",
       "          [0.0000, 2.0063, 3.6411,  ..., 2.3751, 0.0000, 1.7510]],\n",
       "\n",
       "         [[0.6819, 0.0000, 0.6205,  ..., 0.0000, 0.9400, 1.5356],\n",
       "          [0.0000, 1.3500, 1.0352,  ..., 0.8879, 2.3182, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6350, 1.6081, 0.7301],\n",
       "          ...,\n",
       "          [0.4442, 0.0000, 2.1246,  ..., 0.0966, 0.7882, 1.5920],\n",
       "          [1.4873, 0.0000, 0.2683,  ..., 0.0000, 1.6488, 0.2661],\n",
       "          [0.3257, 0.2221, 0.7868,  ..., 0.2541, 1.7204, 0.7284]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.7185, 1.8092, 0.0000,  ..., 0.4413, 0.0000, 0.3170],\n",
       "          [0.4104, 0.8848, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 2.2277, 0.5118,  ..., 0.3384, 2.4265, 0.7051],\n",
       "          ...,\n",
       "          [1.0232, 0.0000, 0.0000,  ..., 0.3878, 1.3228, 0.0000],\n",
       "          [0.3232, 3.1274, 2.9078,  ..., 1.2931, 0.1088, 0.0000],\n",
       "          [0.0000, 0.0000, 2.6110,  ..., 0.0000, 0.2240, 0.0000]],\n",
       "\n",
       "         [[1.8617, 0.0656, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.1593, 0.0000,  ..., 2.3392, 0.9732, 0.0000],\n",
       "          [2.5130, 0.0000, 0.0000,  ..., 0.0000, 1.3642, 0.0000],\n",
       "          ...,\n",
       "          [3.9152, 0.0000, 0.9247,  ..., 0.0000, 0.1743, 1.4785],\n",
       "          [2.7101, 0.0000, 0.0000,  ..., 0.0000, 0.6275, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9267, 0.0572]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.8738, 0.0000],\n",
       "          [0.0000, 0.7810, 1.7678,  ..., 1.5005, 0.0000, 0.8167],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.3869, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 1.4338,  ..., 0.9423, 0.0000, 0.0000],\n",
       "          [0.0000, 1.6954, 2.1104,  ..., 1.6115, 4.0714, 0.0000],\n",
       "          [0.4486, 0.0000, 0.2714,  ..., 2.8716, 0.9764, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "x = torch.rand(1, 32, 48, 48)\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "print(block)\n",
    "block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
