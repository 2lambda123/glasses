{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetBasicBlock(\n",
       "  (block): Residual(\n",
       "    (block): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (1): ConvBnAct(\n",
       "        (conv): DeepthWiseConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
       "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (2): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.mobilenet import MobileNetBasicBlock,MobileNetEncoder\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder\n",
    "\n",
    "\n",
    "MobileNetBasicBlock(16, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 32, 112, 112]             896\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "  DeepthWiseConv2d-4         [-1, 32, 112, 112]             320\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "         Conv2dPad-7         [-1, 16, 112, 112]             528\n",
      "         Conv2dPad-8         [-1, 96, 112, 112]           1,632\n",
      "       BatchNorm2d-9         [-1, 96, 112, 112]             192\n",
      "            ReLU6-10         [-1, 96, 112, 112]               0\n",
      " DeepthWiseConv2d-11           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-12           [-1, 96, 56, 56]             192\n",
      "            ReLU6-13           [-1, 96, 56, 56]               0\n",
      "        Conv2dPad-14           [-1, 24, 56, 56]           2,328\n",
      "      BatchNorm2d-15           [-1, 24, 56, 56]              48\n",
      "MobileNetBasicBlock-16           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-17          [-1, 144, 56, 56]           3,600\n",
      "      BatchNorm2d-18          [-1, 144, 56, 56]             288\n",
      "            ReLU6-19          [-1, 144, 56, 56]               0\n",
      " DeepthWiseConv2d-20          [-1, 144, 56, 56]           1,440\n",
      "      BatchNorm2d-21          [-1, 144, 56, 56]             288\n",
      "            ReLU6-22          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-23           [-1, 24, 56, 56]           3,480\n",
      "      BatchNorm2d-24           [-1, 24, 56, 56]              48\n",
      "         Residual-25           [-1, 24, 56, 56]               0\n",
      "MobileNetBasicBlock-26           [-1, 24, 56, 56]               0\n",
      "   MobileNetLayer-27           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-28          [-1, 144, 56, 56]           3,600\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      " DeepthWiseConv2d-31          [-1, 144, 28, 28]           1,440\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "        Conv2dPad-34           [-1, 32, 28, 28]           4,640\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      "MobileNetBasicBlock-36           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-37          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-40          [-1, 192, 28, 28]           1,920\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "        Conv2dPad-43           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      "         Residual-45           [-1, 32, 28, 28]               0\n",
      "MobileNetBasicBlock-46           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-47          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-48          [-1, 192, 28, 28]             384\n",
      "            ReLU6-49          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-50          [-1, 192, 28, 28]           1,920\n",
      "      BatchNorm2d-51          [-1, 192, 28, 28]             384\n",
      "            ReLU6-52          [-1, 192, 28, 28]               0\n",
      "        Conv2dPad-53           [-1, 32, 28, 28]           6,176\n",
      "      BatchNorm2d-54           [-1, 32, 28, 28]              64\n",
      "         Residual-55           [-1, 32, 28, 28]               0\n",
      "MobileNetBasicBlock-56           [-1, 32, 28, 28]               0\n",
      "   MobileNetLayer-57           [-1, 32, 28, 28]               0\n",
      "        Conv2dPad-58          [-1, 192, 28, 28]           6,336\n",
      "      BatchNorm2d-59          [-1, 192, 28, 28]             384\n",
      "            ReLU6-60          [-1, 192, 28, 28]               0\n",
      " DeepthWiseConv2d-61          [-1, 192, 14, 14]           1,920\n",
      "      BatchNorm2d-62          [-1, 192, 14, 14]             384\n",
      "            ReLU6-63          [-1, 192, 14, 14]               0\n",
      "        Conv2dPad-64           [-1, 64, 14, 14]          12,352\n",
      "      BatchNorm2d-65           [-1, 64, 14, 14]             128\n",
      "MobileNetBasicBlock-66           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-67          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-70          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-71          [-1, 384, 14, 14]             768\n",
      "            ReLU6-72          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-73           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-74           [-1, 64, 14, 14]             128\n",
      "         Residual-75           [-1, 64, 14, 14]               0\n",
      "MobileNetBasicBlock-76           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-77          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-78          [-1, 384, 14, 14]             768\n",
      "            ReLU6-79          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-80          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-81          [-1, 384, 14, 14]             768\n",
      "            ReLU6-82          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-83           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-84           [-1, 64, 14, 14]             128\n",
      "         Residual-85           [-1, 64, 14, 14]               0\n",
      "MobileNetBasicBlock-86           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-87          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-88          [-1, 384, 14, 14]             768\n",
      "            ReLU6-89          [-1, 384, 14, 14]               0\n",
      " DeepthWiseConv2d-90          [-1, 384, 14, 14]           3,840\n",
      "      BatchNorm2d-91          [-1, 384, 14, 14]             768\n",
      "            ReLU6-92          [-1, 384, 14, 14]               0\n",
      "        Conv2dPad-93           [-1, 64, 14, 14]          24,640\n",
      "      BatchNorm2d-94           [-1, 64, 14, 14]             128\n",
      "         Residual-95           [-1, 64, 14, 14]               0\n",
      "MobileNetBasicBlock-96           [-1, 64, 14, 14]               0\n",
      "   MobileNetLayer-97           [-1, 64, 14, 14]               0\n",
      "        Conv2dPad-98          [-1, 384, 14, 14]          24,960\n",
      "      BatchNorm2d-99          [-1, 384, 14, 14]             768\n",
      "           ReLU6-100          [-1, 384, 14, 14]               0\n",
      "DeepthWiseConv2d-101          [-1, 384, 14, 14]           3,840\n",
      "     BatchNorm2d-102          [-1, 384, 14, 14]             768\n",
      "           ReLU6-103          [-1, 384, 14, 14]               0\n",
      "       Conv2dPad-104           [-1, 96, 14, 14]          36,960\n",
      "     BatchNorm2d-105           [-1, 96, 14, 14]             192\n",
      "MobileNetBasicBlock-106           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-107          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-108          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-109          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-110          [-1, 576, 14, 14]           5,760\n",
      "     BatchNorm2d-111          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-112          [-1, 576, 14, 14]               0\n",
      "       Conv2dPad-113           [-1, 96, 14, 14]          55,392\n",
      "     BatchNorm2d-114           [-1, 96, 14, 14]             192\n",
      "        Residual-115           [-1, 96, 14, 14]               0\n",
      "MobileNetBasicBlock-116           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-117          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-118          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-119          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-120          [-1, 576, 14, 14]           5,760\n",
      "     BatchNorm2d-121          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-122          [-1, 576, 14, 14]               0\n",
      "       Conv2dPad-123           [-1, 96, 14, 14]          55,392\n",
      "     BatchNorm2d-124           [-1, 96, 14, 14]             192\n",
      "        Residual-125           [-1, 96, 14, 14]               0\n",
      "MobileNetBasicBlock-126           [-1, 96, 14, 14]               0\n",
      "  MobileNetLayer-127           [-1, 96, 14, 14]               0\n",
      "       Conv2dPad-128          [-1, 576, 14, 14]          55,872\n",
      "     BatchNorm2d-129          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-130          [-1, 576, 14, 14]               0\n",
      "DeepthWiseConv2d-131            [-1, 576, 7, 7]           5,760\n",
      "     BatchNorm2d-132            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-133            [-1, 576, 7, 7]               0\n",
      "       Conv2dPad-134            [-1, 160, 7, 7]          92,320\n",
      "     BatchNorm2d-135            [-1, 160, 7, 7]             320\n",
      "MobileNetBasicBlock-136            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-137            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-138            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-139            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-140            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-141            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-142            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-143            [-1, 160, 7, 7]         153,760\n",
      "     BatchNorm2d-144            [-1, 160, 7, 7]             320\n",
      "        Residual-145            [-1, 160, 7, 7]               0\n",
      "MobileNetBasicBlock-146            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-147            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-148            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-149            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-150            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-151            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-152            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-153            [-1, 160, 7, 7]         153,760\n",
      "     BatchNorm2d-154            [-1, 160, 7, 7]             320\n",
      "        Residual-155            [-1, 160, 7, 7]               0\n",
      "MobileNetBasicBlock-156            [-1, 160, 7, 7]               0\n",
      "  MobileNetLayer-157            [-1, 160, 7, 7]               0\n",
      "       Conv2dPad-158            [-1, 960, 7, 7]         154,560\n",
      "     BatchNorm2d-159            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-160            [-1, 960, 7, 7]               0\n",
      "DeepthWiseConv2d-161            [-1, 960, 7, 7]           9,600\n",
      "     BatchNorm2d-162            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-163            [-1, 960, 7, 7]               0\n",
      "       Conv2dPad-164            [-1, 320, 7, 7]         307,520\n",
      "     BatchNorm2d-165            [-1, 320, 7, 7]             640\n",
      "MobileNetBasicBlock-166            [-1, 320, 7, 7]               0\n",
      "  MobileNetLayer-167            [-1, 320, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 1,827,456\n",
      "Trainable params: 1,827,456\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 151.19\n",
      "Params size (MB): 6.97\n",
      "Estimated Total Size (MB): 158.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "encoder = MobileNetEncoder(\n",
    "#               depths=[1, 2, 1, 1, 1, 1, 1],\n",
    "              block=MobileNetBasicBlock)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "model = encoder.cuda()\n",
    "summary(model, (3, 224, 224))\n",
    "\n",
    "# encoder(x).shape\n",
    "# encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepthWiseConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, groups=out_channels, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 3,504,872\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 13.37\n",
      "Estimated Total Size (MB): 166.81\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model = mobilenet_v2().cuda()\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Add Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 res_func: Callable[[Tensor], Tensor] = None,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "        self.res_func = res_func\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        if self.res_func is not None:\n",
    "            x = self.res_func(x, res)\n",
    "        return x\n",
    "\n",
    "\n",
    "def add(x: Tensor, res: Tensor) -> Tensor:\n",
    "    return x.add_(res)\n",
    "\n",
    "\n",
    "ResidualAdd = partial(Residual, res_func=add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.3 ms ± 6.57 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, block: nn.Module,\n",
    "                 shortcut: nn.Module = None, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        res = x\n",
    "        x = self.block(x)\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        x += res\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.7 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "m = ResidualAdd(nn.Sequential(\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64),\n",
    "                \n",
    "            ))\n",
    "\n",
    "x = torch.rand(1,64, 48, 48)\n",
    "\n",
    "for _ in range(10):\n",
    "    m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (gate): Sequential(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ResNetBasicBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ResnetDecoder(\n",
       "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.utils.PretrainedWeightsProvider import PretrainedWeightsProvider\n",
    "\n",
    "# test if the weights are correct, only for resnet18 \n",
    "PretrainedWeightsProvider()['resnet18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-977f1222c54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNetBasicBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 }\n\u001b[1;32m     68\u001b[0m             )), shortcut=ResNetShorcut(\n\u001b[0;32m---> 69\u001b[0;31m             in_features, out_features * self.expansion, downsampling) if in_features != out_features * self.expansion else None)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/blocks/residuals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, shortcut, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     def __init__(self, block: nn.Module,\n\u001b[1;32m     62\u001b[0m                  shortcut: nn.Module = None, *args, **kwargs):\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "\n",
    "ResNetBasicBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of glasses.nn.models.classification.resnet failed: Traceback (most recent call last):\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/vaevictis/anaconda3/envs/dl/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: forward() requires a code object with 1 free vars, not 0\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'block'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8543bc12316a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(cls, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFrancescoSaverioZuppichini\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mglasses\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdevelop\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0m_static\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mResNet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mresnet18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, n_classes, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0min_channels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mRGB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mGray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, blocks_sizes, depths, activation, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         self.blocks = nn.ModuleList([\n\u001b[1;32m    227\u001b[0m             ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=depths[0], activation=activation,\n\u001b[0;32m--> 228\u001b[0;31m                         block=block,  *args, **kwargs),\n\u001b[0m\u001b[1;32m    229\u001b[0m             *[ResNetLayer(in_channels * block.expansion,\n\u001b[1;32m    230\u001b[0m                           \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, block, n, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         self.block = nn.Sequential(\n\u001b[1;32m    190\u001b[0m             block(in_channels, out_channels, *args,\n\u001b[0;32m--> 191\u001b[0;31m                   downsampling=downsampling,  **kwargs),\n\u001b[0m\u001b[1;32m    192\u001b[0m             *[block(out_channels * block.expansion,\n\u001b[1;32m    193\u001b[0m                     out_channels, *args, **kwargs) for _ in range(n - 1)]\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/classification/resnet/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, activation, downsampling, conv)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mactivation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLUInPlace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsampling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'block'"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification import ResNet\n",
    "\n",
    "\n",
    "ResNet.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetBasicBlock(\n",
      "  (block): Residual(\n",
      "    (block): Sequential(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (shortcut): ResNetShorcut(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (act): ReLU(inplace=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3507, 0.0000, 0.2612,  ..., 0.0000, 0.0000, 1.0867],\n",
       "          [0.0000, 0.9422, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.2224, 0.2569],\n",
       "          ...,\n",
       "          [0.4459, 0.3775, 3.1123,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 1.2234,  ..., 1.2519, 0.0000, 0.7491],\n",
       "          [0.0000, 0.0000, 0.3720,  ..., 0.0000, 0.8578, 0.0000]],\n",
       "\n",
       "         [[0.4809, 0.6557, 2.3329,  ..., 0.0000, 0.0000, 0.7809],\n",
       "          [0.0000, 0.8320, 0.0000,  ..., 0.1316, 1.9552, 0.2474],\n",
       "          [0.0000, 0.7629, 0.2113,  ..., 0.0000, 0.0000, 0.3037],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 2.3773,  ..., 0.0000, 0.0000, 0.6268],\n",
       "          [0.0000, 0.0000, 0.8727,  ..., 1.7412, 0.0000, 0.2877],\n",
       "          [0.0000, 2.0063, 3.6411,  ..., 2.3751, 0.0000, 1.7510]],\n",
       "\n",
       "         [[0.6819, 0.0000, 0.6205,  ..., 0.0000, 0.9400, 1.5356],\n",
       "          [0.0000, 1.3500, 1.0352,  ..., 0.8879, 2.3182, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.6350, 1.6081, 0.7301],\n",
       "          ...,\n",
       "          [0.4442, 0.0000, 2.1246,  ..., 0.0966, 0.7882, 1.5920],\n",
       "          [1.4873, 0.0000, 0.2683,  ..., 0.0000, 1.6488, 0.2661],\n",
       "          [0.3257, 0.2221, 0.7868,  ..., 0.2541, 1.7204, 0.7284]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.7185, 1.8092, 0.0000,  ..., 0.4413, 0.0000, 0.3170],\n",
       "          [0.4104, 0.8848, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 2.2277, 0.5118,  ..., 0.3384, 2.4265, 0.7051],\n",
       "          ...,\n",
       "          [1.0232, 0.0000, 0.0000,  ..., 0.3878, 1.3228, 0.0000],\n",
       "          [0.3232, 3.1274, 2.9078,  ..., 1.2931, 0.1088, 0.0000],\n",
       "          [0.0000, 0.0000, 2.6110,  ..., 0.0000, 0.2240, 0.0000]],\n",
       "\n",
       "         [[1.8617, 0.0656, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.1593, 0.0000,  ..., 2.3392, 0.9732, 0.0000],\n",
       "          [2.5130, 0.0000, 0.0000,  ..., 0.0000, 1.3642, 0.0000],\n",
       "          ...,\n",
       "          [3.9152, 0.0000, 0.9247,  ..., 0.0000, 0.1743, 1.4785],\n",
       "          [2.7101, 0.0000, 0.0000,  ..., 0.0000, 0.6275, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9267, 0.0572]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.8738, 0.0000],\n",
       "          [0.0000, 0.7810, 1.7678,  ..., 1.5005, 0.0000, 0.8167],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.3869, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 1.4338,  ..., 0.9423, 0.0000, 0.0000],\n",
       "          [0.0000, 1.6954, 2.1104,  ..., 1.6115, 4.0714, 0.0000],\n",
       "          [0.4486, 0.0000, 0.2714,  ..., 2.8716, 0.9764, 0.0000]]]],\n",
       "       grad_fn=<ReluBackward1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetBasicBlock\n",
    "\n",
    "x = torch.rand(1, 32, 48, 48)\n",
    "block = ResNetBasicBlock(32, 64)\n",
    "print(block)\n",
    "block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
