{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "URL = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5097, -0.1584, -0.1039,  ..., -0.4699, -0.4895, -0.3134],\n",
       "          [-0.3268, -0.0977,  0.5717,  ...,  0.1253, -0.2982,  0.0250],\n",
       "          [-0.3186,  0.0352,  0.6240,  ..., -0.3029, -0.3958, -0.6869],\n",
       "          ...,\n",
       "          [-0.4024,  0.4335,  0.2689,  ..., -0.9266, -0.0629, -0.7173],\n",
       "          [ 0.0423, -0.1966,  0.1985,  ...,  0.1283,  0.2436,  0.0872],\n",
       "          [-0.1668, -0.1652,  0.2772,  ..., -0.2744, -0.3322, -0.2125]],\n",
       "\n",
       "         [[-0.2416, -0.1410, -0.3617,  ..., -0.4207, -0.4389,  0.0384],\n",
       "          [-0.5749, -0.6739, -0.3115,  ..., -0.2171, -0.1255,  0.0023],\n",
       "          [-0.1302, -0.2923, -0.1579,  ..., -0.1351, -0.0416, -0.3534],\n",
       "          ...,\n",
       "          [-0.0748, -0.3791,  0.0713,  ..., -0.2042, -0.3289,  0.3153],\n",
       "          [-0.4919, -0.7480, -0.2047,  ..., -0.1089,  0.3773, -0.2863],\n",
       "          [ 0.0320, -0.0969,  0.0226,  ...,  0.3943,  0.4132, -0.2187]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from glasses.nn.models.segmentation.unet import UNet, UNetEncoder\n",
    "from glasses.nn.models.classification.senet import SENetBasicBlock\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder, ResNet\n",
    "from glasses.nn.blocks import Conv2dPad\n",
    "from functools import partial\n",
    "x = torch.rand((1, 1, 32 * 12, 32*12))\n",
    "# custom encoder\n",
    "resnet = ResNet.resnet18(in_channels=1)\n",
    "# we need to change the first conv in order to accept a gray image\n",
    "# resnet.encoder.blocks[0].block[0].block.block.conv1 = Conv2dPad(1, 64, kernel_size=1)\n",
    "# unet = UNet(1, n_classes=2, widths=resnet.encoder.widths)\n",
    "# use resnet18 as encoder\n",
    "resnet = ResNet.resnet18(in_channels=1)\n",
    "unet = UNet(1, n_classes=2, widths=resnet.encoder.widths)\n",
    "unet.encoder = resnet.encoder\n",
    "unet(x)\n",
    "\n",
    "unet = UNet(encoder=partial(UNetEncoder, block=SENetBasicBlock))\n",
    "unet(x)\n",
    "\n",
    "encoder = ResNetEncoder(in_channels=1, widths=[64,128,256,512,1024], depths=[2,2,2,2,2])\n",
    "unet = UNet(1, n_classes=2, widths=encoder.widths)\n",
    "unet.encoder = encoder\n",
    "unet(x)\n",
    "# # custom block\n",
    "# unet = UNet(down_block=SENetBasicBlock, up_block=SENetBasicBlock)\n",
    "# unet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "from functools import partial\n",
    "from glasses.nn.blocks import ConvBnAct, Conv2dPad\n",
    "from glasses.nn.models.segmentation.unet import UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification import ResNet\n",
    "from glasses.nn.models.segmentation.unet import  UNet\n",
    "\n",
    "resnet34 = ResNet.resnet18()\n",
    "# we need to change the first conv in order to accept a gray image\n",
    "resnet34.encoder.blocks[0].block[0].block.block.conv1 = Conv2dPad(1, 64, kernel_size=1)\n",
    "\n",
    "unet = UNet(1, n_classes=2, blocks_sizes=resnet34.encoder.blocks_sizes)\n",
    "\n",
    "unet.encoder.blocks = resnet34.encoder.blocks\n",
    "\n",
    "x = torch.rand((1, 1, 32 * 12, 32*12))\n",
    "unet(x).shape\n",
    "\n",
    "# unet.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.senet import SENetBasicBlock\n",
    "\n",
    "block = SENetBasicBlock\n",
    "\n",
    "unet = UNet(down_block=SENetBasicBlock, up_block=SENetBasicBlock)\n",
    "\n",
    "x = torch.rand((1, 1, 32 * 12, 32*12))\n",
    "unet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(n_classes=4)\n",
    "unet(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[r.shape for r in unet.residuals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.mobilenet import InvertedResidualBlock\n",
    "from glasses.nn.models.classification.se import SEModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UpBlock(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
