{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNetEncoder, ResNetBottleneckBlock, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "         Conv2dPad-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "         Conv2dPad-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "        Conv2dPad-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "        Conv2dPad-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "    ResNetShorcut-15          [-1, 256, 56, 56]               0\n",
      "      ResidualAdd-16          [-1, 256, 56, 56]               0\n",
      "             ReLU-17          [-1, 256, 56, 56]               0\n",
      "ResNetBottleneckBlock-18          [-1, 256, 56, 56]               0\n",
      "        Conv2dPad-19           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "        Conv2dPad-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "        Conv2dPad-25          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-26          [-1, 256, 56, 56]             512\n",
      "      ResidualAdd-27          [-1, 256, 56, 56]               0\n",
      "             ReLU-28          [-1, 256, 56, 56]               0\n",
      "ResNetBottleneckBlock-29          [-1, 256, 56, 56]               0\n",
      "        Conv2dPad-30           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "        Conv2dPad-33           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-34           [-1, 64, 56, 56]             128\n",
      "             ReLU-35           [-1, 64, 56, 56]               0\n",
      "        Conv2dPad-36          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-37          [-1, 256, 56, 56]             512\n",
      "      ResidualAdd-38          [-1, 256, 56, 56]               0\n",
      "             ReLU-39          [-1, 256, 56, 56]               0\n",
      "ResNetBottleneckBlock-40          [-1, 256, 56, 56]               0\n",
      "      ResNetLayer-41          [-1, 256, 56, 56]               0\n",
      "        Conv2dPad-42          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-43          [-1, 128, 56, 56]             256\n",
      "             ReLU-44          [-1, 128, 56, 56]               0\n",
      "        Conv2dPad-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-48          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-49          [-1, 512, 28, 28]           1,024\n",
      "        Conv2dPad-50          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-51          [-1, 512, 28, 28]           1,024\n",
      "    ResNetShorcut-52          [-1, 512, 28, 28]               0\n",
      "      ResidualAdd-53          [-1, 512, 28, 28]               0\n",
      "             ReLU-54          [-1, 512, 28, 28]               0\n",
      "ResNetBottleneckBlock-55          [-1, 512, 28, 28]               0\n",
      "        Conv2dPad-56          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-59          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-62          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-63          [-1, 512, 28, 28]           1,024\n",
      "      ResidualAdd-64          [-1, 512, 28, 28]               0\n",
      "             ReLU-65          [-1, 512, 28, 28]               0\n",
      "ResNetBottleneckBlock-66          [-1, 512, 28, 28]               0\n",
      "        Conv2dPad-67          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-70          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-71          [-1, 128, 28, 28]             256\n",
      "             ReLU-72          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-73          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-74          [-1, 512, 28, 28]           1,024\n",
      "      ResidualAdd-75          [-1, 512, 28, 28]               0\n",
      "             ReLU-76          [-1, 512, 28, 28]               0\n",
      "ResNetBottleneckBlock-77          [-1, 512, 28, 28]               0\n",
      "        Conv2dPad-78          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-81          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-82          [-1, 128, 28, 28]             256\n",
      "             ReLU-83          [-1, 128, 28, 28]               0\n",
      "        Conv2dPad-84          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-85          [-1, 512, 28, 28]           1,024\n",
      "      ResidualAdd-86          [-1, 512, 28, 28]               0\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "ResNetBottleneckBlock-88          [-1, 512, 28, 28]               0\n",
      "      ResNetLayer-89          [-1, 512, 28, 28]               0\n",
      "        Conv2dPad-90          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-91          [-1, 256, 28, 28]             512\n",
      "             ReLU-92          [-1, 256, 28, 28]               0\n",
      "        Conv2dPad-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "        Conv2dPad-96         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-97         [-1, 1024, 14, 14]           2,048\n",
      "        Conv2dPad-98         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-99         [-1, 1024, 14, 14]           2,048\n",
      "   ResNetShorcut-100         [-1, 1024, 14, 14]               0\n",
      "     ResidualAdd-101         [-1, 1024, 14, 14]               0\n",
      "            ReLU-102         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-103         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-104          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-107          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-108          [-1, 256, 14, 14]             512\n",
      "            ReLU-109          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-110         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-111         [-1, 1024, 14, 14]           2,048\n",
      "     ResidualAdd-112         [-1, 1024, 14, 14]               0\n",
      "            ReLU-113         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-114         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-115          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-116          [-1, 256, 14, 14]             512\n",
      "            ReLU-117          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-118          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-119          [-1, 256, 14, 14]             512\n",
      "            ReLU-120          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-121         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-122         [-1, 1024, 14, 14]           2,048\n",
      "     ResidualAdd-123         [-1, 1024, 14, 14]               0\n",
      "            ReLU-124         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-125         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-126          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-127          [-1, 256, 14, 14]             512\n",
      "            ReLU-128          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-129          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-130          [-1, 256, 14, 14]             512\n",
      "            ReLU-131          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-132         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-133         [-1, 1024, 14, 14]           2,048\n",
      "     ResidualAdd-134         [-1, 1024, 14, 14]               0\n",
      "            ReLU-135         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-136         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-137          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-138          [-1, 256, 14, 14]             512\n",
      "            ReLU-139          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-140          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-141          [-1, 256, 14, 14]             512\n",
      "            ReLU-142          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-143         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-144         [-1, 1024, 14, 14]           2,048\n",
      "     ResidualAdd-145         [-1, 1024, 14, 14]               0\n",
      "            ReLU-146         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-147         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-148          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-149          [-1, 256, 14, 14]             512\n",
      "            ReLU-150          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-151          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "       Conv2dPad-154         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-155         [-1, 1024, 14, 14]           2,048\n",
      "     ResidualAdd-156         [-1, 1024, 14, 14]               0\n",
      "            ReLU-157         [-1, 1024, 14, 14]               0\n",
      "ResNetBottleneckBlock-158         [-1, 1024, 14, 14]               0\n",
      "     ResNetLayer-159         [-1, 1024, 14, 14]               0\n",
      "       Conv2dPad-160          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-161          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-162          [-1, 512, 14, 14]               0\n",
      "       Conv2dPad-163            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "       Conv2dPad-166           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-167           [-1, 2048, 7, 7]           4,096\n",
      "       Conv2dPad-168           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-169           [-1, 2048, 7, 7]           4,096\n",
      "   ResNetShorcut-170           [-1, 2048, 7, 7]               0\n",
      "     ResidualAdd-171           [-1, 2048, 7, 7]               0\n",
      "            ReLU-172           [-1, 2048, 7, 7]               0\n",
      "ResNetBottleneckBlock-173           [-1, 2048, 7, 7]               0\n",
      "       Conv2dPad-174            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-175            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-176            [-1, 512, 7, 7]               0\n",
      "       Conv2dPad-177            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-178            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-179            [-1, 512, 7, 7]               0\n",
      "       Conv2dPad-180           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-181           [-1, 2048, 7, 7]           4,096\n",
      "     ResidualAdd-182           [-1, 2048, 7, 7]               0\n",
      "            ReLU-183           [-1, 2048, 7, 7]               0\n",
      "ResNetBottleneckBlock-184           [-1, 2048, 7, 7]               0\n",
      "       Conv2dPad-185            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-186            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-187            [-1, 512, 7, 7]               0\n",
      "       Conv2dPad-188            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-189            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-190            [-1, 512, 7, 7]               0\n",
      "       Conv2dPad-191           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-192           [-1, 2048, 7, 7]           4,096\n",
      "     ResidualAdd-193           [-1, 2048, 7, 7]               0\n",
      "            ReLU-194           [-1, 2048, 7, 7]               0\n",
      "ResNetBottleneckBlock-195           [-1, 2048, 7, 7]               0\n",
      "     ResNetLayer-196           [-1, 2048, 7, 7]               0\n",
      "   ResNetEncoder-197           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-198           [-1, 2048, 1, 1]               0\n",
      "         Flatten-199                 [-1, 2048]               0\n",
      "          Linear-200                 [-1, 1000]       2,049,000\n",
      "          ResNet-201                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 352.43\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 450.49\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(25557032), tensor(25557032))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1,3,224,224))\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(ResNet.resnet50().cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "          ResNet-175                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.57\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.63\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(25557032), tensor(25557032))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "summary(resnet50().cuda(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FishNetEncoder(\n",
       "  (gate): Sequential(\n",
       "    (0): ConvBnAct(\n",
       "      (conv): Conv2dPad(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): ConvBnAct(\n",
       "      (conv): Conv2dPad(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): ConvBnAct(\n",
       "      (conv): Conv2dPad(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (tail): FishNetTail(\n",
       "    (gate): Sequential(\n",
       "      (conv): Conv2dPad(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): ReLU(inplace=True)\n",
       "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2dPad(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2dPad(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2dPad(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2dPad(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2dPad(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2dPad(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2dPad(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2dPad(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): ResNetBasicBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (conv1): Conv2dPad(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act1): ReLU(inplace=True)\n",
       "                (conv2): Conv2dPad(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "              (shortcut): ResNetShorcut(\n",
       "                (conv): Conv2dPad(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.fishnet import *\n",
    "\n",
    "FishNetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0772,  0.2468,  0.0378,  ..., -0.0923, -0.1824,  0.1713],\n",
       "          [ 0.3918,  0.2547,  0.3007,  ...,  0.0977,  0.0139, -0.2737],\n",
       "          [ 0.5582,  0.0309,  0.1796,  ...,  0.1827, -0.1732, -0.2105],\n",
       "          ...,\n",
       "          [ 0.0686,  0.4146,  0.1586,  ..., -0.2502,  0.1623, -0.3160],\n",
       "          [-0.3456,  0.1369, -0.1815,  ...,  0.5352, -0.1767, -0.1576],\n",
       "          [ 0.2580,  0.4078,  0.2556,  ...,  0.3599,  0.1640,  0.2413]],\n",
       "\n",
       "         [[ 0.0381,  0.2632, -0.0644,  ..., -0.3150,  0.2631,  0.2014],\n",
       "          [-0.0441, -0.1492,  0.4175,  ...,  0.4077,  0.6664,  0.5212],\n",
       "          [ 0.1247,  0.0249, -0.4995,  ..., -0.8009, -0.4319, -0.3534],\n",
       "          ...,\n",
       "          [-0.6494,  0.2061,  0.4023,  ...,  0.5828,  0.0681, -0.5076],\n",
       "          [ 0.1859, -0.0686, -0.4607,  ...,  0.1644,  0.2183, -0.5342],\n",
       "          [-0.2189, -0.0205,  0.1018,  ...,  0.0332,  0.0322,  0.2061]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.resnet import ResNet, ResNetBottleneckBlock, ResNetEncoder, ResNetBasicBlock\n",
    "from glasses.nn.models.classification.densenet import DenseNet, DenseNetEncoder, TransitionBlock\n",
    "from glasses.nn.models.classification.mobilenet import MobileNetEncoder\n",
    "from glasses.nn.models.segmentation.unet import UNet, UNetEncoder\n",
    "from functools import partial\n",
    "from torchsummary import summary\n",
    "\n",
    "x = torch.rand((1,1,224,224))\n",
    "\n",
    "unet = UNet(1, n_classes=2)\n",
    "unet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1280, 7, 7]) torch.Size([1, 320, 7, 7])\n",
      "res torch.Size([1, 320, 13, 13]) pad, (3, 3, 3, 3)\n",
      "up torch.Size([1, 320, 14, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 13 and 14 in dimension 2 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-17e3d7b2eb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMobileNetEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# summary(unet, (1,224,224))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, res)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'res {res.shape} pad, {pad}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'up {x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 13 and 14 in dimension 2 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "x = torch.rand((1,1,224,224))\n",
    "unet = UNet(encoder=MobileNetEncoder)\n",
    "unet(x)\n",
    "\n",
    "# summary(unet, (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 16, 112, 112]), torch.Size([1, 24, 56, 56]), torch.Size([1, 32, 28, 28]), torch.Size([1, 64, 14, 14]), torch.Size([1, 96, 14, 14]), torch.Size([1, 160, 7, 7]), torch.Size([1, 320, 7, 7]), torch.Size([1, 1280, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "from glasses.nn.models.classification import MobileNetV2\n",
    "\n",
    "model =MobileNetV2()\n",
    "features = []\n",
    "x = torch.rand((1,3,224,224))\n",
    "\n",
    "x = model.encoder.gate(x)\n",
    "for block in model.encoder.blocks:\n",
    "    x = block(x)\n",
    "    features.append(x)\n",
    "print([x.shape for x in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 248, 7, 7]) torch.Size([1, 120, 7, 7])\n",
      "up torch.Size([1, 120, 14, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 7 and 14 in dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-9030caab9771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDenseNetEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(unet.encoder.widths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# unet.decoder.in_out_block_sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/glasses/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, res)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'up {x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 7 and 14 in dimension 2"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "x = torch.rand((1,1,224,224))\n",
    "unet = UNet(encoder=DenseNetEncoder)\n",
    "unet(x)\n",
    "# print(unet.encoder.widths)\n",
    "# unet.decoder.in_out_block_sizes\n",
    "# summary(unet.encoder, (1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetDecoder(\n",
       "  (blocks): ModuleList(\n",
       "    (0): UpLayer(\n",
       "      (up): ConvTranspose2d(248, 120, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (block): UNetBasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ConvBnAct(\n",
       "              (conv): Conv2dPad(240, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnAct(\n",
       "              (conv): Conv2dPad(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): UpLayer(\n",
       "      (up): ConvTranspose2d(120, 112, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (block): UNetBasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ConvBnAct(\n",
       "              (conv): Conv2dPad(224, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnAct(\n",
       "              (conv): Conv2dPad(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpLayer(\n",
       "      (up): ConvTranspose2d(112, 96, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (block): UNetBasicBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): ConvBnAct(\n",
       "              (conv): Conv2dPad(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): ConvBnAct(\n",
       "              (conv): Conv2dPad(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 28, 28])\n",
      "torch.Size([1, 112, 14, 14])\n",
      "torch.Size([1, 120, 7, 7])\n",
      "torch.Size([1, 248, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "model = DenseNetEncoder()\n",
    "x = torch.rand((1,3,224,224))\n",
    "x = model.gate(x)\n",
    "for block in model.blocks:\n",
    "    x = block(x)\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNetEncoder(\n",
       "  (gate): Sequential(\n",
       "    (conv): Conv2dPad(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act): ReLU(inplace=True)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): DenseNetLayer(\n",
       "      (block): Sequential(\n",
       "        (0): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): TransitionBlock(\n",
       "          (block): Sequential(\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DenseNetLayer(\n",
       "      (block): Sequential(\n",
       "        (0): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): TransitionBlock(\n",
       "          (block): Sequential(\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): DenseNetLayer(\n",
       "      (block): Sequential(\n",
       "        (0): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (17): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (19): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (20): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (22): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (23): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): TransitionBlock(\n",
       "          (block): Sequential(\n",
       "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DenseNetLayer(\n",
       "      (block): Sequential(\n",
       "        (0): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): DenseBottleNeckBlock(\n",
       "          (block): Residual(\n",
       "            (block): Sequential(\n",
       "              (bn1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act1): ReLU(inplace=True)\n",
       "              (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act2): ReLU(inplace=True)\n",
       "              (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (16): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "from functools import partial\n",
    "from glasses.nn.blocks import ConvBnAct, Conv2dPad\n",
    "from glasses.nn.models.segmentation.unet import UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 48, 112, 112]           1,296\n",
      "       BatchNorm2d-2         [-1, 48, 112, 112]              96\n",
      "             Swish-3         [-1, 48, 112, 112]               0\n",
      "   DepthWiseConv2d-4         [-1, 48, 112, 112]             432\n",
      "       BatchNorm2d-5         [-1, 48, 112, 112]              96\n",
      "             Swish-6         [-1, 48, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 48, 1, 1]               0\n",
      "            Conv2d-8             [-1, 12, 1, 1]             588\n",
      "             Swish-9             [-1, 12, 1, 1]               0\n",
      "           Conv2d-10             [-1, 48, 1, 1]             624\n",
      "          Sigmoid-11             [-1, 48, 1, 1]               0\n",
      "        ChannelSE-12         [-1, 48, 112, 112]               0\n",
      "        Conv2dPad-13         [-1, 24, 112, 112]           1,152\n",
      "      BatchNorm2d-14         [-1, 24, 112, 112]              48\n",
      "         Residual-15         [-1, 24, 112, 112]               0\n",
      "EfficientNetBasicBlock-16         [-1, 24, 112, 112]               0\n",
      "  DepthWiseConv2d-17         [-1, 24, 112, 112]             216\n",
      "      BatchNorm2d-18         [-1, 24, 112, 112]              48\n",
      "            Swish-19         [-1, 24, 112, 112]               0\n",
      "AdaptiveAvgPool2d-20             [-1, 24, 1, 1]               0\n",
      "           Conv2d-21              [-1, 6, 1, 1]             150\n",
      "            Swish-22              [-1, 6, 1, 1]               0\n",
      "           Conv2d-23             [-1, 24, 1, 1]             168\n",
      "          Sigmoid-24             [-1, 24, 1, 1]               0\n",
      "        ChannelSE-25         [-1, 24, 112, 112]               0\n",
      "        Conv2dPad-26         [-1, 24, 112, 112]             576\n",
      "      BatchNorm2d-27         [-1, 24, 112, 112]              48\n",
      "        Dropout2d-28         [-1, 24, 112, 112]               0\n",
      "      ResidualAdd-29         [-1, 24, 112, 112]               0\n",
      "EfficientNetBasicBlock-30         [-1, 24, 112, 112]               0\n",
      "  DepthWiseConv2d-31         [-1, 24, 112, 112]             216\n",
      "      BatchNorm2d-32         [-1, 24, 112, 112]              48\n",
      "            Swish-33         [-1, 24, 112, 112]               0\n",
      "AdaptiveAvgPool2d-34             [-1, 24, 1, 1]               0\n",
      "           Conv2d-35              [-1, 6, 1, 1]             150\n",
      "            Swish-36              [-1, 6, 1, 1]               0\n",
      "           Conv2d-37             [-1, 24, 1, 1]             168\n",
      "          Sigmoid-38             [-1, 24, 1, 1]               0\n",
      "        ChannelSE-39         [-1, 24, 112, 112]               0\n",
      "        Conv2dPad-40         [-1, 24, 112, 112]             576\n",
      "      BatchNorm2d-41         [-1, 24, 112, 112]              48\n",
      "        Dropout2d-42         [-1, 24, 112, 112]               0\n",
      "      ResidualAdd-43         [-1, 24, 112, 112]               0\n",
      "EfficientNetBasicBlock-44         [-1, 24, 112, 112]               0\n",
      "EfficientNetLayer-45         [-1, 24, 112, 112]               0\n",
      "        Conv2dPad-46        [-1, 144, 112, 112]           3,456\n",
      "      BatchNorm2d-47        [-1, 144, 112, 112]             288\n",
      "            Swish-48        [-1, 144, 112, 112]               0\n",
      "  DepthWiseConv2d-49          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-50          [-1, 144, 56, 56]             288\n",
      "            Swish-51          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-52            [-1, 144, 1, 1]               0\n",
      "           Conv2d-53              [-1, 6, 1, 1]             870\n",
      "            Swish-54              [-1, 6, 1, 1]               0\n",
      "           Conv2d-55            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-56            [-1, 144, 1, 1]               0\n",
      "        ChannelSE-57          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-58           [-1, 40, 56, 56]           5,760\n",
      "      BatchNorm2d-59           [-1, 40, 56, 56]              80\n",
      "         Residual-60           [-1, 40, 56, 56]               0\n",
      "EfficientNetBasicBlock-61           [-1, 40, 56, 56]               0\n",
      "        Conv2dPad-62          [-1, 240, 56, 56]           9,600\n",
      "      BatchNorm2d-63          [-1, 240, 56, 56]             480\n",
      "            Swish-64          [-1, 240, 56, 56]               0\n",
      "  DepthWiseConv2d-65          [-1, 240, 56, 56]           2,160\n",
      "      BatchNorm2d-66          [-1, 240, 56, 56]             480\n",
      "            Swish-67          [-1, 240, 56, 56]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
      "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
      "            Swish-70             [-1, 10, 1, 1]               0\n",
      "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-73          [-1, 240, 56, 56]               0\n",
      "        Conv2dPad-74           [-1, 40, 56, 56]           9,600\n",
      "      BatchNorm2d-75           [-1, 40, 56, 56]              80\n",
      "        Dropout2d-76           [-1, 40, 56, 56]               0\n",
      "      ResidualAdd-77           [-1, 40, 56, 56]               0\n",
      "EfficientNetBasicBlock-78           [-1, 40, 56, 56]               0\n",
      "        Conv2dPad-79          [-1, 240, 56, 56]           9,600\n",
      "      BatchNorm2d-80          [-1, 240, 56, 56]             480\n",
      "            Swish-81          [-1, 240, 56, 56]               0\n",
      "  DepthWiseConv2d-82          [-1, 240, 56, 56]           2,160\n",
      "      BatchNorm2d-83          [-1, 240, 56, 56]             480\n",
      "            Swish-84          [-1, 240, 56, 56]               0\n",
      "AdaptiveAvgPool2d-85            [-1, 240, 1, 1]               0\n",
      "           Conv2d-86             [-1, 10, 1, 1]           2,410\n",
      "            Swish-87             [-1, 10, 1, 1]               0\n",
      "           Conv2d-88            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-89            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-90          [-1, 240, 56, 56]               0\n",
      "        Conv2dPad-91           [-1, 40, 56, 56]           9,600\n",
      "      BatchNorm2d-92           [-1, 40, 56, 56]              80\n",
      "        Dropout2d-93           [-1, 40, 56, 56]               0\n",
      "      ResidualAdd-94           [-1, 40, 56, 56]               0\n",
      "EfficientNetBasicBlock-95           [-1, 40, 56, 56]               0\n",
      "        Conv2dPad-96          [-1, 240, 56, 56]           9,600\n",
      "      BatchNorm2d-97          [-1, 240, 56, 56]             480\n",
      "            Swish-98          [-1, 240, 56, 56]               0\n",
      "  DepthWiseConv2d-99          [-1, 240, 56, 56]           2,160\n",
      "     BatchNorm2d-100          [-1, 240, 56, 56]             480\n",
      "           Swish-101          [-1, 240, 56, 56]               0\n",
      "AdaptiveAvgPool2d-102            [-1, 240, 1, 1]               0\n",
      "          Conv2d-103             [-1, 10, 1, 1]           2,410\n",
      "           Swish-104             [-1, 10, 1, 1]               0\n",
      "          Conv2d-105            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-106            [-1, 240, 1, 1]               0\n",
      "       ChannelSE-107          [-1, 240, 56, 56]               0\n",
      "       Conv2dPad-108           [-1, 40, 56, 56]           9,600\n",
      "     BatchNorm2d-109           [-1, 40, 56, 56]              80\n",
      "       Dropout2d-110           [-1, 40, 56, 56]               0\n",
      "     ResidualAdd-111           [-1, 40, 56, 56]               0\n",
      "EfficientNetBasicBlock-112           [-1, 40, 56, 56]               0\n",
      "       Conv2dPad-113          [-1, 240, 56, 56]           9,600\n",
      "     BatchNorm2d-114          [-1, 240, 56, 56]             480\n",
      "           Swish-115          [-1, 240, 56, 56]               0\n",
      " DepthWiseConv2d-116          [-1, 240, 56, 56]           2,160\n",
      "     BatchNorm2d-117          [-1, 240, 56, 56]             480\n",
      "           Swish-118          [-1, 240, 56, 56]               0\n",
      "AdaptiveAvgPool2d-119            [-1, 240, 1, 1]               0\n",
      "          Conv2d-120             [-1, 10, 1, 1]           2,410\n",
      "           Swish-121             [-1, 10, 1, 1]               0\n",
      "          Conv2d-122            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-123            [-1, 240, 1, 1]               0\n",
      "       ChannelSE-124          [-1, 240, 56, 56]               0\n",
      "       Conv2dPad-125           [-1, 40, 56, 56]           9,600\n",
      "     BatchNorm2d-126           [-1, 40, 56, 56]              80\n",
      "       Dropout2d-127           [-1, 40, 56, 56]               0\n",
      "     ResidualAdd-128           [-1, 40, 56, 56]               0\n",
      "EfficientNetBasicBlock-129           [-1, 40, 56, 56]               0\n",
      "EfficientNetLayer-130           [-1, 40, 56, 56]               0\n",
      "       Conv2dPad-131          [-1, 240, 56, 56]           9,600\n",
      "     BatchNorm2d-132          [-1, 240, 56, 56]             480\n",
      "           Swish-133          [-1, 240, 56, 56]               0\n",
      " DepthWiseConv2d-134          [-1, 240, 28, 28]           6,000\n",
      "     BatchNorm2d-135          [-1, 240, 28, 28]             480\n",
      "           Swish-136          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-137            [-1, 240, 1, 1]               0\n",
      "          Conv2d-138             [-1, 10, 1, 1]           2,410\n",
      "           Swish-139             [-1, 10, 1, 1]               0\n",
      "          Conv2d-140            [-1, 240, 1, 1]           2,640\n",
      "         Sigmoid-141            [-1, 240, 1, 1]               0\n",
      "       ChannelSE-142          [-1, 240, 28, 28]               0\n",
      "       Conv2dPad-143           [-1, 64, 28, 28]          15,360\n",
      "     BatchNorm2d-144           [-1, 64, 28, 28]             128\n",
      "        Residual-145           [-1, 64, 28, 28]               0\n",
      "EfficientNetBasicBlock-146           [-1, 64, 28, 28]               0\n",
      "       Conv2dPad-147          [-1, 384, 28, 28]          24,576\n",
      "     BatchNorm2d-148          [-1, 384, 28, 28]             768\n",
      "           Swish-149          [-1, 384, 28, 28]               0\n",
      " DepthWiseConv2d-150          [-1, 384, 28, 28]           9,600\n",
      "     BatchNorm2d-151          [-1, 384, 28, 28]             768\n",
      "           Swish-152          [-1, 384, 28, 28]               0\n",
      "AdaptiveAvgPool2d-153            [-1, 384, 1, 1]               0\n",
      "          Conv2d-154             [-1, 16, 1, 1]           6,160\n",
      "           Swish-155             [-1, 16, 1, 1]               0\n",
      "          Conv2d-156            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-157            [-1, 384, 1, 1]               0\n",
      "       ChannelSE-158          [-1, 384, 28, 28]               0\n",
      "       Conv2dPad-159           [-1, 64, 28, 28]          24,576\n",
      "     BatchNorm2d-160           [-1, 64, 28, 28]             128\n",
      "       Dropout2d-161           [-1, 64, 28, 28]               0\n",
      "     ResidualAdd-162           [-1, 64, 28, 28]               0\n",
      "EfficientNetBasicBlock-163           [-1, 64, 28, 28]               0\n",
      "       Conv2dPad-164          [-1, 384, 28, 28]          24,576\n",
      "     BatchNorm2d-165          [-1, 384, 28, 28]             768\n",
      "           Swish-166          [-1, 384, 28, 28]               0\n",
      " DepthWiseConv2d-167          [-1, 384, 28, 28]           9,600\n",
      "     BatchNorm2d-168          [-1, 384, 28, 28]             768\n",
      "           Swish-169          [-1, 384, 28, 28]               0\n",
      "AdaptiveAvgPool2d-170            [-1, 384, 1, 1]               0\n",
      "          Conv2d-171             [-1, 16, 1, 1]           6,160\n",
      "           Swish-172             [-1, 16, 1, 1]               0\n",
      "          Conv2d-173            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-174            [-1, 384, 1, 1]               0\n",
      "       ChannelSE-175          [-1, 384, 28, 28]               0\n",
      "       Conv2dPad-176           [-1, 64, 28, 28]          24,576\n",
      "     BatchNorm2d-177           [-1, 64, 28, 28]             128\n",
      "       Dropout2d-178           [-1, 64, 28, 28]               0\n",
      "     ResidualAdd-179           [-1, 64, 28, 28]               0\n",
      "EfficientNetBasicBlock-180           [-1, 64, 28, 28]               0\n",
      "       Conv2dPad-181          [-1, 384, 28, 28]          24,576\n",
      "     BatchNorm2d-182          [-1, 384, 28, 28]             768\n",
      "           Swish-183          [-1, 384, 28, 28]               0\n",
      " DepthWiseConv2d-184          [-1, 384, 28, 28]           9,600\n",
      "     BatchNorm2d-185          [-1, 384, 28, 28]             768\n",
      "           Swish-186          [-1, 384, 28, 28]               0\n",
      "AdaptiveAvgPool2d-187            [-1, 384, 1, 1]               0\n",
      "          Conv2d-188             [-1, 16, 1, 1]           6,160\n",
      "           Swish-189             [-1, 16, 1, 1]               0\n",
      "          Conv2d-190            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-191            [-1, 384, 1, 1]               0\n",
      "       ChannelSE-192          [-1, 384, 28, 28]               0\n",
      "       Conv2dPad-193           [-1, 64, 28, 28]          24,576\n",
      "     BatchNorm2d-194           [-1, 64, 28, 28]             128\n",
      "       Dropout2d-195           [-1, 64, 28, 28]               0\n",
      "     ResidualAdd-196           [-1, 64, 28, 28]               0\n",
      "EfficientNetBasicBlock-197           [-1, 64, 28, 28]               0\n",
      "       Conv2dPad-198          [-1, 384, 28, 28]          24,576\n",
      "     BatchNorm2d-199          [-1, 384, 28, 28]             768\n",
      "           Swish-200          [-1, 384, 28, 28]               0\n",
      " DepthWiseConv2d-201          [-1, 384, 28, 28]           9,600\n",
      "     BatchNorm2d-202          [-1, 384, 28, 28]             768\n",
      "           Swish-203          [-1, 384, 28, 28]               0\n",
      "AdaptiveAvgPool2d-204            [-1, 384, 1, 1]               0\n",
      "          Conv2d-205             [-1, 16, 1, 1]           6,160\n",
      "           Swish-206             [-1, 16, 1, 1]               0\n",
      "          Conv2d-207            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-208            [-1, 384, 1, 1]               0\n",
      "       ChannelSE-209          [-1, 384, 28, 28]               0\n",
      "       Conv2dPad-210           [-1, 64, 28, 28]          24,576\n",
      "     BatchNorm2d-211           [-1, 64, 28, 28]             128\n",
      "       Dropout2d-212           [-1, 64, 28, 28]               0\n",
      "     ResidualAdd-213           [-1, 64, 28, 28]               0\n",
      "EfficientNetBasicBlock-214           [-1, 64, 28, 28]               0\n",
      "EfficientNetLayer-215           [-1, 64, 28, 28]               0\n",
      "       Conv2dPad-216          [-1, 384, 28, 28]          24,576\n",
      "     BatchNorm2d-217          [-1, 384, 28, 28]             768\n",
      "           Swish-218          [-1, 384, 28, 28]               0\n",
      " DepthWiseConv2d-219          [-1, 384, 14, 14]           3,456\n",
      "     BatchNorm2d-220          [-1, 384, 14, 14]             768\n",
      "           Swish-221          [-1, 384, 14, 14]               0\n",
      "AdaptiveAvgPool2d-222            [-1, 384, 1, 1]               0\n",
      "          Conv2d-223             [-1, 16, 1, 1]           6,160\n",
      "           Swish-224             [-1, 16, 1, 1]               0\n",
      "          Conv2d-225            [-1, 384, 1, 1]           6,528\n",
      "         Sigmoid-226            [-1, 384, 1, 1]               0\n",
      "       ChannelSE-227          [-1, 384, 14, 14]               0\n",
      "       Conv2dPad-228          [-1, 128, 14, 14]          49,152\n",
      "     BatchNorm2d-229          [-1, 128, 14, 14]             256\n",
      "        Residual-230          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-231          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-232          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-233          [-1, 768, 14, 14]           1,536\n",
      "           Swish-234          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-235          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-236          [-1, 768, 14, 14]           1,536\n",
      "           Swish-237          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-238            [-1, 768, 1, 1]               0\n",
      "          Conv2d-239             [-1, 32, 1, 1]          24,608\n",
      "           Swish-240             [-1, 32, 1, 1]               0\n",
      "          Conv2d-241            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-242            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-243          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-244          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-245          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-246          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-247          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-248          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-249          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-250          [-1, 768, 14, 14]           1,536\n",
      "           Swish-251          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-252          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-253          [-1, 768, 14, 14]           1,536\n",
      "           Swish-254          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-255            [-1, 768, 1, 1]               0\n",
      "          Conv2d-256             [-1, 32, 1, 1]          24,608\n",
      "           Swish-257             [-1, 32, 1, 1]               0\n",
      "          Conv2d-258            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-259            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-260          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-261          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-262          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-263          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-264          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-265          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-266          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-267          [-1, 768, 14, 14]           1,536\n",
      "           Swish-268          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-269          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-270          [-1, 768, 14, 14]           1,536\n",
      "           Swish-271          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-272            [-1, 768, 1, 1]               0\n",
      "          Conv2d-273             [-1, 32, 1, 1]          24,608\n",
      "           Swish-274             [-1, 32, 1, 1]               0\n",
      "          Conv2d-275            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-276            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-277          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-278          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-279          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-280          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-281          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-282          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-283          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-284          [-1, 768, 14, 14]           1,536\n",
      "           Swish-285          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-286          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-287          [-1, 768, 14, 14]           1,536\n",
      "           Swish-288          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-289            [-1, 768, 1, 1]               0\n",
      "          Conv2d-290             [-1, 32, 1, 1]          24,608\n",
      "           Swish-291             [-1, 32, 1, 1]               0\n",
      "          Conv2d-292            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-293            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-294          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-295          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-296          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-297          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-298          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-299          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-300          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-301          [-1, 768, 14, 14]           1,536\n",
      "           Swish-302          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-303          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-304          [-1, 768, 14, 14]           1,536\n",
      "           Swish-305          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-306            [-1, 768, 1, 1]               0\n",
      "          Conv2d-307             [-1, 32, 1, 1]          24,608\n",
      "           Swish-308             [-1, 32, 1, 1]               0\n",
      "          Conv2d-309            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-310            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-311          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-312          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-313          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-314          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-315          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-316          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-317          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-318          [-1, 768, 14, 14]           1,536\n",
      "           Swish-319          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-320          [-1, 768, 14, 14]           6,912\n",
      "     BatchNorm2d-321          [-1, 768, 14, 14]           1,536\n",
      "           Swish-322          [-1, 768, 14, 14]               0\n",
      "AdaptiveAvgPool2d-323            [-1, 768, 1, 1]               0\n",
      "          Conv2d-324             [-1, 32, 1, 1]          24,608\n",
      "           Swish-325             [-1, 32, 1, 1]               0\n",
      "          Conv2d-326            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-327            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-328          [-1, 768, 14, 14]               0\n",
      "       Conv2dPad-329          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-330          [-1, 128, 14, 14]             256\n",
      "       Dropout2d-331          [-1, 128, 14, 14]               0\n",
      "     ResidualAdd-332          [-1, 128, 14, 14]               0\n",
      "EfficientNetBasicBlock-333          [-1, 128, 14, 14]               0\n",
      "EfficientNetLayer-334          [-1, 128, 14, 14]               0\n",
      "       Conv2dPad-335          [-1, 768, 14, 14]          98,304\n",
      "     BatchNorm2d-336          [-1, 768, 14, 14]           1,536\n",
      "           Swish-337          [-1, 768, 14, 14]               0\n",
      " DepthWiseConv2d-338            [-1, 768, 7, 7]          19,200\n",
      "     BatchNorm2d-339            [-1, 768, 7, 7]           1,536\n",
      "           Swish-340            [-1, 768, 7, 7]               0\n",
      "AdaptiveAvgPool2d-341            [-1, 768, 1, 1]               0\n",
      "          Conv2d-342             [-1, 32, 1, 1]          24,608\n",
      "           Swish-343             [-1, 32, 1, 1]               0\n",
      "          Conv2d-344            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-345            [-1, 768, 1, 1]               0\n",
      "       ChannelSE-346            [-1, 768, 7, 7]               0\n",
      "       Conv2dPad-347            [-1, 176, 7, 7]         135,168\n",
      "     BatchNorm2d-348            [-1, 176, 7, 7]             352\n",
      "        Residual-349            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-350            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-351           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-352           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-353           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-354           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-355           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-356           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-357           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-358             [-1, 44, 1, 1]          46,508\n",
      "           Swish-359             [-1, 44, 1, 1]               0\n",
      "          Conv2d-360           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-361           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-362           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-363            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-364            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-365            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-366            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-367            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-368           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-369           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-370           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-371           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-372           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-373           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-374           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-375             [-1, 44, 1, 1]          46,508\n",
      "           Swish-376             [-1, 44, 1, 1]               0\n",
      "          Conv2d-377           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-378           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-379           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-380            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-381            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-382            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-383            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-384            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-385           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-386           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-387           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-388           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-389           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-390           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-391           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-392             [-1, 44, 1, 1]          46,508\n",
      "           Swish-393             [-1, 44, 1, 1]               0\n",
      "          Conv2d-394           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-395           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-396           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-397            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-398            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-399            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-400            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-401            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-402           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-403           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-404           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-405           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-406           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-407           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-408           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-409             [-1, 44, 1, 1]          46,508\n",
      "           Swish-410             [-1, 44, 1, 1]               0\n",
      "          Conv2d-411           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-412           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-413           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-414            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-415            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-416            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-417            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-418            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-419           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-420           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-421           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-422           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-423           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-424           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-425           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-426             [-1, 44, 1, 1]          46,508\n",
      "           Swish-427             [-1, 44, 1, 1]               0\n",
      "          Conv2d-428           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-429           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-430           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-431            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-432            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-433            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-434            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-435            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-436           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-437           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-438           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-439           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-440           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-441           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-442           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-443             [-1, 44, 1, 1]          46,508\n",
      "           Swish-444             [-1, 44, 1, 1]               0\n",
      "          Conv2d-445           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-446           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-447           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-448            [-1, 176, 7, 7]         185,856\n",
      "     BatchNorm2d-449            [-1, 176, 7, 7]             352\n",
      "       Dropout2d-450            [-1, 176, 7, 7]               0\n",
      "     ResidualAdd-451            [-1, 176, 7, 7]               0\n",
      "EfficientNetBasicBlock-452            [-1, 176, 7, 7]               0\n",
      "EfficientNetLayer-453            [-1, 176, 7, 7]               0\n",
      "       Conv2dPad-454           [-1, 1056, 7, 7]         185,856\n",
      "     BatchNorm2d-455           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-456           [-1, 1056, 7, 7]               0\n",
      " DepthWiseConv2d-457           [-1, 1056, 7, 7]          26,400\n",
      "     BatchNorm2d-458           [-1, 1056, 7, 7]           2,112\n",
      "           Swish-459           [-1, 1056, 7, 7]               0\n",
      "AdaptiveAvgPool2d-460           [-1, 1056, 1, 1]               0\n",
      "          Conv2d-461             [-1, 44, 1, 1]          46,508\n",
      "           Swish-462             [-1, 44, 1, 1]               0\n",
      "          Conv2d-463           [-1, 1056, 1, 1]          47,520\n",
      "         Sigmoid-464           [-1, 1056, 1, 1]               0\n",
      "       ChannelSE-465           [-1, 1056, 7, 7]               0\n",
      "       Conv2dPad-466            [-1, 304, 7, 7]         321,024\n",
      "     BatchNorm2d-467            [-1, 304, 7, 7]             608\n",
      "        Residual-468            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-469            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-470           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-471           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-472           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-473           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-474           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-475           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-476           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-477             [-1, 76, 1, 1]         138,700\n",
      "           Swish-478             [-1, 76, 1, 1]               0\n",
      "          Conv2d-479           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-480           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-481           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-482            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-483            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-484            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-485            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-486            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-487           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-488           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-489           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-490           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-491           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-492           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-493           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-494             [-1, 76, 1, 1]         138,700\n",
      "           Swish-495             [-1, 76, 1, 1]               0\n",
      "          Conv2d-496           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-497           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-498           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-499            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-500            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-501            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-502            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-503            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-504           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-505           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-506           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-507           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-508           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-509           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-510           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-511             [-1, 76, 1, 1]         138,700\n",
      "           Swish-512             [-1, 76, 1, 1]               0\n",
      "          Conv2d-513           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-514           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-515           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-516            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-517            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-518            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-519            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-520            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-521           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-522           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-523           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-524           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-525           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-526           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-527           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-528             [-1, 76, 1, 1]         138,700\n",
      "           Swish-529             [-1, 76, 1, 1]               0\n",
      "          Conv2d-530           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-531           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-532           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-533            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-534            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-535            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-536            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-537            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-538           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-539           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-540           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-541           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-542           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-543           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-544           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-545             [-1, 76, 1, 1]         138,700\n",
      "           Swish-546             [-1, 76, 1, 1]               0\n",
      "          Conv2d-547           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-548           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-549           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-550            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-551            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-552            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-553            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-554            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-555           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-556           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-557           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-558           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-559           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-560           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-561           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-562             [-1, 76, 1, 1]         138,700\n",
      "           Swish-563             [-1, 76, 1, 1]               0\n",
      "          Conv2d-564           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-565           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-566           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-567            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-568            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-569            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-570            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-571            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-572           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-573           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-574           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-575           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-576           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-577           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-578           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-579             [-1, 76, 1, 1]         138,700\n",
      "           Swish-580             [-1, 76, 1, 1]               0\n",
      "          Conv2d-581           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-582           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-583           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-584            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-585            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-586            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-587            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-588            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-589           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-590           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-591           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-592           [-1, 1824, 7, 7]          45,600\n",
      "     BatchNorm2d-593           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-594           [-1, 1824, 7, 7]               0\n",
      "AdaptiveAvgPool2d-595           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-596             [-1, 76, 1, 1]         138,700\n",
      "           Swish-597             [-1, 76, 1, 1]               0\n",
      "          Conv2d-598           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-599           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-600           [-1, 1824, 7, 7]               0\n",
      "       Conv2dPad-601            [-1, 304, 7, 7]         554,496\n",
      "     BatchNorm2d-602            [-1, 304, 7, 7]             608\n",
      "       Dropout2d-603            [-1, 304, 7, 7]               0\n",
      "     ResidualAdd-604            [-1, 304, 7, 7]               0\n",
      "EfficientNetBasicBlock-605            [-1, 304, 7, 7]               0\n",
      "EfficientNetLayer-606            [-1, 304, 7, 7]               0\n",
      "       Conv2dPad-607           [-1, 1824, 7, 7]         554,496\n",
      "     BatchNorm2d-608           [-1, 1824, 7, 7]           3,648\n",
      "           Swish-609           [-1, 1824, 7, 7]               0\n",
      " DepthWiseConv2d-610           [-1, 1824, 4, 4]          16,416\n",
      "     BatchNorm2d-611           [-1, 1824, 4, 4]           3,648\n",
      "           Swish-612           [-1, 1824, 4, 4]               0\n",
      "AdaptiveAvgPool2d-613           [-1, 1824, 1, 1]               0\n",
      "          Conv2d-614             [-1, 76, 1, 1]         138,700\n",
      "           Swish-615             [-1, 76, 1, 1]               0\n",
      "          Conv2d-616           [-1, 1824, 1, 1]         140,448\n",
      "         Sigmoid-617           [-1, 1824, 1, 1]               0\n",
      "       ChannelSE-618           [-1, 1824, 4, 4]               0\n",
      "       Conv2dPad-619            [-1, 512, 4, 4]         933,888\n",
      "     BatchNorm2d-620            [-1, 512, 4, 4]           1,024\n",
      "        Residual-621            [-1, 512, 4, 4]               0\n",
      "EfficientNetBasicBlock-622            [-1, 512, 4, 4]               0\n",
      "       Conv2dPad-623           [-1, 3072, 4, 4]       1,572,864\n",
      "     BatchNorm2d-624           [-1, 3072, 4, 4]           6,144\n",
      "           Swish-625           [-1, 3072, 4, 4]               0\n",
      " DepthWiseConv2d-626           [-1, 3072, 4, 4]          27,648\n",
      "     BatchNorm2d-627           [-1, 3072, 4, 4]           6,144\n",
      "           Swish-628           [-1, 3072, 4, 4]               0\n",
      "AdaptiveAvgPool2d-629           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-630            [-1, 128, 1, 1]         393,344\n",
      "           Swish-631            [-1, 128, 1, 1]               0\n",
      "          Conv2d-632           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-633           [-1, 3072, 1, 1]               0\n",
      "       ChannelSE-634           [-1, 3072, 4, 4]               0\n",
      "       Conv2dPad-635            [-1, 512, 4, 4]       1,572,864\n",
      "     BatchNorm2d-636            [-1, 512, 4, 4]           1,024\n",
      "       Dropout2d-637            [-1, 512, 4, 4]               0\n",
      "     ResidualAdd-638            [-1, 512, 4, 4]               0\n",
      "EfficientNetBasicBlock-639            [-1, 512, 4, 4]               0\n",
      "       Conv2dPad-640           [-1, 3072, 4, 4]       1,572,864\n",
      "     BatchNorm2d-641           [-1, 3072, 4, 4]           6,144\n",
      "           Swish-642           [-1, 3072, 4, 4]               0\n",
      " DepthWiseConv2d-643           [-1, 3072, 4, 4]          27,648\n",
      "     BatchNorm2d-644           [-1, 3072, 4, 4]           6,144\n",
      "           Swish-645           [-1, 3072, 4, 4]               0\n",
      "AdaptiveAvgPool2d-646           [-1, 3072, 1, 1]               0\n",
      "          Conv2d-647            [-1, 128, 1, 1]         393,344\n",
      "           Swish-648            [-1, 128, 1, 1]               0\n",
      "          Conv2d-649           [-1, 3072, 1, 1]         396,288\n",
      "         Sigmoid-650           [-1, 3072, 1, 1]               0\n",
      "       ChannelSE-651           [-1, 3072, 4, 4]               0\n",
      "       Conv2dPad-652            [-1, 512, 4, 4]       1,572,864\n",
      "     BatchNorm2d-653            [-1, 512, 4, 4]           1,024\n",
      "       Dropout2d-654            [-1, 512, 4, 4]               0\n",
      "     ResidualAdd-655            [-1, 512, 4, 4]               0\n",
      "EfficientNetBasicBlock-656            [-1, 512, 4, 4]               0\n",
      "EfficientNetLayer-657            [-1, 512, 4, 4]               0\n",
      "       Conv2dPad-658           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-659           [-1, 2048, 4, 4]           4,096\n",
      "           Swish-660           [-1, 2048, 4, 4]               0\n",
      "EfficientNetEncoder-661           [-1, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-662           [-1, 2048, 1, 1]               0\n",
      "       Dropout2d-663                 [-1, 2048]               0\n",
      "          Linear-664                 [-1, 1000]       2,049,000\n",
      "MobileNetDecoder-665                 [-1, 1000]               0\n",
      "    EfficientNet-666                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 30,389,784\n",
      "Trainable params: 30,389,784\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 566.42\n",
      "Params size (MB): 115.93\n",
      "Estimated Total Size (MB): 682.92\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30389784"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.classification.efficientnet import EfficientNet\n",
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_dst  = EfficientNet.b5()\n",
    "\n",
    "info = summary(model_dst.to(device), (3,224,224))\n",
    "\n",
    "# model_dst\n",
    "\n",
    "info[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (encoder): MobileNetEncoder(\n",
       "    (gate): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2dPad(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "                  (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidualBlock(\n",
       "            (block): ResidualAdd(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MobileNetLayer(\n",
       "        (block): Sequential(\n",
       "          (0): InvertedResidualBlock(\n",
       "            (block): Residual(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): DepthWiseConv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "                  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (conv): Conv2dPad(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2dPad(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): ReLU6()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): MobileNetDecoder(\n",
       "    (avg): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (drop): Dropout2d(p=0.2, inplace=False)\n",
       "    (fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.utils.PretrainedWeightsProvider import PretrainedWeightsProvider\n",
    "\n",
    "provider = PretrainedWeightsProvider()\n",
    "\n",
    "provider['mobilenet_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.3545e-01,  4.4536e-01,  4.2809e-02, -7.1374e-01,  3.6706e-01,\n",
       "          2.3940e-01, -1.3259e+00, -3.2074e-01, -1.6859e+00, -7.2495e-01,\n",
       "         -1.2006e+00, -5.1331e-01, -7.6875e-01, -1.4668e+00, -8.2695e-01,\n",
       "         -4.0084e-02,  3.0943e-01, -7.2798e-01, -4.7880e-01, -8.8295e-01,\n",
       "         -1.6215e+00,  7.9493e-01,  3.6127e-02, -5.1066e-01, -4.0636e-01,\n",
       "         -8.5400e-01, -1.2117e+00, -2.1563e-01, -1.1900e+00, -5.3588e-01,\n",
       "         -9.6766e-01, -8.8796e-01, -1.2135e+00, -6.0439e-01, -7.0122e-01,\n",
       "         -1.4644e+00, -1.1432e+00, -9.4588e-01, -9.1610e-01, -1.1081e+00,\n",
       "         -7.2389e-01, -8.2417e-01, -8.6236e-01, -1.3655e+00, -1.6005e+00,\n",
       "         -1.3012e-01, -1.6388e+00, -7.9500e-01, -1.2640e+00, -1.1749e+00,\n",
       "         -1.2268e+00, -4.6094e-01, -7.8901e-01, -1.4785e+00, -2.4503e+00,\n",
       "         -5.8356e-01, -1.4344e+00, -6.2406e-01, -1.2202e+00, -3.8103e-01,\n",
       "         -1.2667e+00, -7.2553e-01, -1.5403e+00, -2.9658e-01, -7.7501e-01,\n",
       "         -4.5203e-01, -1.2975e+00, -1.3473e+00, -1.2312e+00, -7.0520e-02,\n",
       "         -6.6595e-01, -3.0047e-01, -1.2305e+00, -4.0677e-01, -6.3327e-01,\n",
       "         -7.5752e-01, -1.5412e+00, -7.2333e-01, -3.8013e-01,  2.9596e-01,\n",
       "         -2.1835e-01,  7.4517e-02, -1.0002e+00, -7.1870e-01, -7.1186e-01,\n",
       "         -1.9088e-01, -8.1453e-01,  6.6486e-01,  3.3098e-01,  7.6313e-01,\n",
       "         -4.0929e-01, -1.4285e-01,  8.8520e-01, -4.0011e-01, -4.7286e-01,\n",
       "         -1.2093e+00, -1.6921e-01,  7.8092e-02, -1.7125e-01, -6.1036e-01,\n",
       "         -1.1505e+00, -1.4207e+00, -3.5481e-01, -7.3372e-01, -7.2086e-01,\n",
       "         -1.0551e+00, -8.7694e-02,  6.0089e-01, -3.2373e-01, -7.4009e-01,\n",
       "         -1.0168e+00,  4.8691e-01, -7.4767e-01, -2.3184e-01, -1.2725e+00,\n",
       "         -1.3634e+00, -7.9397e-01, -3.9978e-01, -7.3932e-01, -8.7324e-01,\n",
       "         -7.7167e-01, -3.8495e-02, -5.0902e-01, -4.1823e-01, -1.2341e+00,\n",
       "         -3.0809e-01,  1.4983e-01,  2.8842e-01,  1.4587e-01, -5.1855e-01,\n",
       "         -4.3862e-01, -1.3440e+00, -6.7721e-01, -2.6529e-01, -1.1127e+00,\n",
       "         -3.8541e-01, -1.2754e+00, -9.5725e-01, -6.2672e-01, -1.7871e-01,\n",
       "         -5.5845e-01, -2.8105e-01, -6.0216e-01, -6.3757e-01, -9.4824e-01,\n",
       "         -2.6211e-01, -1.9991e-01, -1.1126e-03, -8.6987e-01, -1.3223e-01,\n",
       "         -9.9629e-01, -1.2198e-01, -1.0008e+00, -1.6549e-01, -6.3627e-01,\n",
       "         -6.2685e-01, -7.6135e-01, -7.6975e-01, -1.2315e+00,  1.5163e-01,\n",
       "         -1.1215e+00,  9.2939e-01, -2.4741e-01,  1.1405e-01, -9.7754e-01,\n",
       "         -8.5576e-01, -4.8485e-01,  3.0590e-01, -1.2531e+00, -3.5677e-01,\n",
       "          9.2963e-02, -5.6811e-01,  4.9142e-02, -1.1587e+00,  3.5926e-01,\n",
       "         -5.2492e-01, -9.9007e-01, -4.9710e-01, -1.0377e-01, -3.6572e-01,\n",
       "         -1.0159e+00, -3.7744e-01, -1.2447e+00, -7.1996e-01, -1.1030e+00,\n",
       "         -5.2797e-01, -1.5869e+00, -6.6538e-01, -6.1210e-01,  7.2187e-01,\n",
       "         -1.7151e-02,  4.6285e-01, -1.4857e+00, -2.4993e-01, -1.2238e+00,\n",
       "         -6.7601e-01, -3.1937e-01, -4.8104e-01, -6.0049e-01, -2.2733e-01,\n",
       "         -1.0297e+00, -3.2216e-01, -9.6157e-01, -3.4484e-01, -6.6400e-01,\n",
       "         -5.2466e-01, -1.0534e+00, -8.3249e-01, -3.2130e-01, -2.0843e-01,\n",
       "         -2.5442e-01, -7.1815e-01, -7.1042e-01, -8.2449e-01, -5.3275e-01,\n",
       "         -1.2542e+00, -4.9687e-01, -6.9443e-01, -4.3130e-01, -5.3612e-01,\n",
       "         -7.0501e-01, -3.5008e-01, -1.3100e-01,  2.4521e-01, -3.2668e-01,\n",
       "         -3.8033e-01, -3.3440e-01, -7.1523e-01, -2.4298e-01, -2.0388e-01,\n",
       "         -8.9900e-01, -7.2012e-01, -9.2422e-01, -4.4133e-01, -2.4140e-01,\n",
       "         -6.4029e-01, -6.1730e-01, -1.0485e+00,  4.5875e-01,  2.6364e-01,\n",
       "          4.7315e-03, -3.5119e-01, -8.1451e-01, -5.7275e-01, -4.6467e-01,\n",
       "          2.3264e-02, -9.0405e-02, -1.3064e-01, -8.4855e-01,  2.1377e-01,\n",
       "         -7.1263e-02,  7.7122e-01, -6.5919e-01, -5.9555e-01,  6.4456e-01,\n",
       "         -2.2899e-01, -1.1483e+00, -4.1863e-01,  1.4469e-01, -2.5103e-01,\n",
       "          4.1499e-03,  3.9619e-01, -9.2769e-01, -7.0219e-01, -1.2403e+00,\n",
       "         -3.8883e-01, -1.6413e+00, -1.7241e+00, -1.6445e+00, -9.8397e-01,\n",
       "         -7.5014e-01, -1.2899e+00, -1.1936e+00, -1.1962e+00, -1.1076e+00,\n",
       "         -3.9163e-01, -9.3182e-01, -1.2316e+00, -3.3587e-01, -4.6952e-01,\n",
       "         -1.4276e+00,  3.9467e-01,  2.4822e-01,  5.4007e-01, -2.2881e-01,\n",
       "         -1.7463e-01, -5.0481e-01, -1.8495e-02, -8.8582e-01,  1.3964e-01,\n",
       "         -4.5635e-01, -9.4016e-01, -4.0164e-01,  4.0427e-01, -7.2788e-01,\n",
       "         -6.2644e-01,  4.4453e-01, -4.5542e-01, -1.4131e+00, -2.9387e-01,\n",
       "         -9.1144e-01, -5.9863e-01, -1.5142e+00, -1.3289e+00, -9.8658e-01,\n",
       "         -1.2832e+00, -6.6550e-01, -2.1992e-01, -7.0171e-01, -5.0486e-01,\n",
       "         -4.3665e-01, -9.9991e-01, -9.3611e-01, -4.0737e-01,  8.2831e-01,\n",
       "         -9.3981e-01, -5.5373e-01, -9.7072e-01, -4.9881e-01, -2.8852e-02,\n",
       "         -1.1154e+00, -1.4151e+00, -1.5726e+00, -2.8581e-01, -1.3192e+00,\n",
       "         -1.1233e+00, -1.7253e+00, -9.1415e-01, -5.0495e-01, -7.4756e-01,\n",
       "         -4.9855e-01, -4.1215e-01, -5.6683e-01, -4.9979e-01, -9.1667e-01,\n",
       "         -1.2816e+00, -6.1560e-01, -9.4282e-01, -3.0415e-01, -1.2723e+00,\n",
       "         -7.5472e-01, -1.7533e+00, -9.1104e-01, -3.1456e-01, -9.2125e-01,\n",
       "         -7.1300e-01, -5.1075e-01, -5.8525e-01,  5.0208e-01,  4.2327e-03,\n",
       "          4.3540e-01,  1.6161e-01,  7.4160e-02, -2.6609e-01,  7.3909e-01,\n",
       "         -1.0732e+00, -5.6052e-01, -9.7661e-01, -3.8058e-01, -6.2700e-01,\n",
       "         -6.9836e-01, -6.6631e-01, -7.0049e-01, -1.1166e+00, -6.3086e-01,\n",
       "         -1.1543e+00, -7.7003e-01, -3.6564e-01, -2.6759e-01, -7.1436e-01,\n",
       "         -1.1049e+00, -9.2042e-01, -1.2782e+00, -5.0866e-01, -8.4603e-01,\n",
       "         -1.3547e+00, -4.1294e-01, -1.8684e+00, -6.5502e-01, -7.2516e-01,\n",
       "         -1.5500e+00, -5.7725e-01, -1.0817e+00, -8.0733e-01, -1.4422e+00,\n",
       "         -2.0722e-01, -1.1900e+00, -8.9468e-01, -4.0583e-01, -1.1361e+00,\n",
       "         -9.2994e-01, -1.9313e+00, -4.5656e-03, -8.3126e-01, -1.1563e+00,\n",
       "         -1.1549e+00, -7.9573e-01, -1.0675e+00,  1.6694e+00,  6.8503e-01,\n",
       "         -5.4648e-01, -1.3807e-01,  6.0775e-01, -1.0685e+00,  9.2247e-01,\n",
       "          1.2551e+00,  5.3440e-01, -9.6560e-01, -1.5430e+00,  2.2739e+00,\n",
       "         -9.9087e-01,  1.1325e-01,  1.5765e+00, -5.1085e-01,  5.1085e-01,\n",
       "         -1.6137e-01,  1.8181e+00,  1.0859e+00,  1.0545e+00,  8.7421e-01,\n",
       "          1.5306e-02,  1.8074e+00, -5.3521e-01,  2.5436e-02,  1.2423e+00,\n",
       "          6.8414e-01,  6.4592e-01, -6.6042e-01, -6.2910e-01,  2.6412e-01,\n",
       "          8.7662e-01, -3.2616e-01,  2.1759e-01,  3.6449e-01,  1.3812e+00,\n",
       "          2.4634e+00, -3.3754e-02,  1.2570e+00, -5.0824e-01, -1.0364e+00,\n",
       "          9.7873e-02, -3.0546e-01,  1.2777e+00,  2.0585e-01, -3.9886e-01,\n",
       "         -2.0019e-01,  3.3544e+00, -2.0427e-01,  7.5190e-01, -5.5205e-01,\n",
       "         -4.7985e-01,  6.1140e-02, -5.6615e-01,  1.2874e+00, -2.9719e-01,\n",
       "          6.9172e-02,  1.0631e+00,  6.9977e-02,  6.3494e-01,  4.0464e-01,\n",
       "         -6.0558e-01, -4.5404e-01,  2.1540e+00,  9.2638e-03, -3.6185e-01,\n",
       "         -1.5137e-01, -3.2678e-01, -3.6085e-01,  8.3325e-02, -2.6285e-01,\n",
       "          4.1581e-01, -2.9903e-01, -6.1732e-01,  1.5522e+00,  3.7412e-01,\n",
       "         -5.4457e-01, -4.9112e-01, -1.0234e-01,  2.9429e+00, -4.6406e-01,\n",
       "          2.4617e+00,  9.4525e-01,  7.1571e-01, -6.0246e-01, -3.0162e-02,\n",
       "          5.1669e-01, -3.8535e-01,  1.4475e+00,  2.5435e-01,  1.3404e+00,\n",
       "         -1.5758e+00, -2.3895e-01,  2.3078e+00,  1.5742e+00,  2.0226e-01,\n",
       "          2.0380e-01,  8.9104e-01,  1.1925e+00,  2.1513e+00,  1.0098e+00,\n",
       "         -1.0883e+00, -8.9217e-02, -6.3654e-01,  4.3442e-01,  4.0420e-01,\n",
       "          1.3219e+00, -4.1648e-02,  9.0205e-01,  1.3443e+00, -3.9474e-01,\n",
       "         -6.4447e-01,  2.7028e-01,  6.6189e-01, -5.3454e-02, -4.8323e-02,\n",
       "         -1.4657e-01, -2.0462e-01,  2.2063e+00, -3.9348e-01,  1.3951e+00,\n",
       "          1.9195e+00, -1.5209e-01, -6.8603e-02,  8.0078e-01, -5.6891e-01,\n",
       "         -1.0826e+00,  1.8833e+00,  2.3392e+00,  6.6285e-01,  1.2698e-01,\n",
       "          2.2210e+00, -2.2038e-01,  7.8772e-01, -1.0583e-01,  2.8533e+00,\n",
       "          3.0141e-01, -1.1698e+00, -5.0273e-01,  1.0261e+00,  2.7757e+00,\n",
       "          6.7795e-01, -1.4851e-01,  5.6162e-01,  5.8464e-01, -9.6339e-01,\n",
       "          2.0915e+00,  8.1536e-01, -2.8795e-01,  1.2583e+00,  4.8863e+00,\n",
       "         -4.1567e-02,  1.3393e+00,  5.0559e-01,  2.1780e+00,  4.2639e-01,\n",
       "         -2.1930e-01,  3.9963e+00,  1.0849e+00, -1.2049e-01,  4.0003e-01,\n",
       "         -2.3146e-01, -1.8590e-01,  1.0718e-01,  1.2067e+00,  5.7461e-01,\n",
       "         -1.9602e-01, -6.8957e-01, -2.8196e-01, -1.5433e-01, -1.5717e-01,\n",
       "         -5.3871e-02,  6.5415e-02,  3.2394e-01, -3.0024e-03,  6.7722e-01,\n",
       "         -1.0246e+00, -9.8381e-01,  4.9247e-01,  1.0352e+00,  1.0309e+00,\n",
       "         -4.6011e-01, -1.0513e+00, -6.3932e-01,  9.4229e-01,  9.4411e-01,\n",
       "          3.5151e-01, -5.5069e-01,  1.2616e+00,  1.1020e+00,  1.4118e+00,\n",
       "          8.2923e-01,  1.8392e+00,  1.4652e+00,  1.1291e+00,  1.1500e+00,\n",
       "          4.7892e-01, -1.3793e-01,  4.8632e-02,  3.4174e+00, -1.1083e-01,\n",
       "          1.9495e+00,  4.6493e-01,  9.1863e-01, -7.4972e-01,  9.9728e-01,\n",
       "          1.9641e+00,  1.6771e+00, -2.6052e-01,  1.7407e+00, -3.9647e-01,\n",
       "          1.4603e-01,  1.5760e+00, -4.9663e-01,  1.5467e+00,  1.3952e+00,\n",
       "         -5.6500e-01,  6.9844e-01,  5.9820e-02,  1.1459e+00,  1.8026e+00,\n",
       "          2.6342e+00,  5.9067e-01, -8.0867e-03,  6.5746e-01, -2.9211e-01,\n",
       "         -3.4061e-01,  1.0230e+00, -6.5723e-01, -2.0106e-01,  1.1024e+00,\n",
       "         -2.3199e-01,  3.8810e-01,  1.6051e+00,  3.2021e-01, -1.6303e+00,\n",
       "          3.1850e-01,  7.5567e-01,  3.3726e-01, -1.9332e-01, -5.2441e-01,\n",
       "         -3.6201e-01, -1.1761e-01,  2.0766e-01,  2.3354e-01,  1.1783e+00,\n",
       "         -4.2972e-01,  3.3978e-01, -7.0577e-02,  3.2271e+00,  3.3064e-01,\n",
       "          1.6371e+00,  2.4406e+00, -1.2739e+00, -6.0924e-01, -5.5593e-01,\n",
       "         -5.4093e-01, -1.4893e+00,  1.3508e-01, -5.4787e-01, -1.8320e-01,\n",
       "         -2.8526e-01, -7.0280e-01,  1.8409e+00,  3.9435e-01,  3.2569e+00,\n",
       "          5.7111e-01,  3.6098e-01, -4.8812e-01, -1.1535e-01,  9.3333e-01,\n",
       "          4.5985e-01, -3.6776e-01,  6.8952e-01,  2.2929e+00,  1.6004e+00,\n",
       "          3.8918e-01,  4.0025e-01,  4.1317e-01, -6.3980e-01, -1.3535e-01,\n",
       "          2.0085e-01,  2.4836e+00,  6.5664e-01,  3.4529e-01,  3.3178e-01,\n",
       "         -1.2521e+00,  9.7008e-01,  1.0652e-02,  2.6177e+00, -2.0029e-01,\n",
       "         -7.6184e-01, -9.7734e-01,  1.1510e+00, -7.8414e-01, -9.9503e-01,\n",
       "          5.8181e-01,  1.5584e+00,  7.0366e-02,  5.6576e-02,  1.3451e+00,\n",
       "          1.3842e+00,  7.6060e-01,  6.8195e-01, -5.5408e-01,  1.3262e+00,\n",
       "         -1.0258e+00,  1.1103e+00,  1.2237e+00,  3.4611e-01,  1.5305e+00,\n",
       "          5.9006e-01,  1.0116e+00, -1.6378e+00,  2.1451e+00,  2.2874e-01,\n",
       "         -5.2084e-01, -1.0831e-01, -4.0566e-01,  1.2283e+00,  3.7742e-01,\n",
       "          3.9376e-01, -4.6980e-01,  8.9801e-01, -3.8667e-01, -1.3019e-02,\n",
       "          1.0592e-01,  7.1895e-01,  2.0418e-01,  9.6068e-01,  1.0352e+00,\n",
       "          1.2150e-01,  1.6476e+00,  4.0657e-01,  1.8587e-01, -8.4203e-01,\n",
       "          3.4970e-01,  1.3674e+00,  3.2975e-01,  4.2149e-01, -9.6775e-01,\n",
       "          2.6194e-01,  2.0899e+00,  2.0103e+00, -7.8196e-01,  3.7866e-01,\n",
       "          1.6960e+00,  1.8205e-01, -9.3352e-02,  1.5521e-01,  1.0603e+00,\n",
       "          7.6606e-01, -4.0230e-01,  6.9343e-01,  1.2041e+00,  1.2357e+00,\n",
       "          1.8921e-01, -2.7428e-01,  2.7814e-01, -1.5527e+00,  1.6055e-01,\n",
       "          2.0924e+00,  1.0626e+00,  7.3662e-01,  5.0955e-01,  2.3206e-01,\n",
       "          1.0936e+00, -8.0482e-01,  1.5465e+00, -8.4101e-01,  1.9459e+00,\n",
       "          3.0462e-01,  2.4284e+00,  1.0909e+00,  8.2478e-01, -3.3905e-01,\n",
       "         -6.3568e-01,  8.5133e-01,  2.2349e-01,  1.5561e+00,  7.6959e-01,\n",
       "          8.8343e-01,  5.8619e-01,  2.7183e+00,  4.1463e-01,  2.1948e-01,\n",
       "         -1.6719e+00,  1.6901e+00, -3.2587e-01,  3.5218e-01,  5.3376e+00,\n",
       "          8.9660e-01,  5.8238e-01,  6.6134e-01,  1.2816e+00,  1.9265e+00,\n",
       "         -2.9094e-01, -6.2242e-01,  6.1186e-01,  7.2028e-01,  3.5710e+00,\n",
       "          2.0401e-01, -5.2192e-01, -8.9361e-01, -2.8391e-01,  1.7417e+00,\n",
       "          1.1973e-01,  4.1254e-01,  2.0741e+00, -3.5320e-01, -2.0699e-01,\n",
       "          9.1301e-01,  1.9571e+00,  8.0459e-01,  1.3038e-01, -3.6605e-01,\n",
       "         -8.6087e-01, -1.2037e-01, -1.9257e-01,  1.3616e+00,  1.7788e-01,\n",
       "         -2.8843e-01, -3.1987e-01, -6.6097e-01,  4.4652e-01,  5.7006e-01,\n",
       "         -4.7581e-01,  1.3288e+00,  1.4464e+00,  2.7664e-01, -9.6707e-01,\n",
       "         -2.8892e-01,  1.8909e+00, -1.3742e-02, -3.5176e-01,  2.9715e-01,\n",
       "          6.8296e-02,  6.7978e-02,  2.2794e-01,  1.0466e-01, -5.2054e-02,\n",
       "          2.4242e+00, -5.5080e-01, -6.6105e-02,  6.4577e-01,  1.5731e+00,\n",
       "          1.1526e+00,  2.0943e+00, -4.4551e-01,  7.1207e-01, -2.5646e-01,\n",
       "         -2.3243e-01,  2.7539e+00,  1.0481e+00, -4.2795e-01,  1.5042e+00,\n",
       "          1.6042e-04, -3.6444e-01,  2.0280e-01,  1.6937e+00,  1.5550e+00,\n",
       "          4.1666e-01,  1.7831e+00, -1.5391e-02,  1.9792e-01, -9.7342e-01,\n",
       "         -7.5168e-01, -2.4252e-01,  4.1491e-01,  1.9390e+00, -7.8845e-02,\n",
       "          4.6263e-01,  6.5544e-01,  1.1326e+00,  6.8601e-01, -1.2005e+00,\n",
       "          2.1317e-01,  1.5798e+00,  3.7031e-01,  4.9823e-02,  9.2495e-01,\n",
       "         -6.5759e-01,  7.5728e-01,  1.6243e+00,  7.9245e-01, -2.6362e-01,\n",
       "         -1.8932e-01,  1.4540e+00,  8.6388e-02, -3.6847e-01, -5.8301e-01,\n",
       "          6.4125e-01, -1.8152e-01,  3.1941e+00,  1.6973e+00,  3.7447e+00,\n",
       "          5.3421e-01,  2.4118e+00,  2.2275e+00, -6.7084e-02, -2.1873e-01,\n",
       "          1.2367e+00, -3.0032e-01,  8.7156e-01,  9.0274e-01,  2.3011e+00,\n",
       "          2.9301e+00,  1.7818e-01, -1.4812e-01,  2.7599e-01,  1.2942e-02,\n",
       "          1.0847e+00,  2.3013e-01, -3.5473e-01,  1.0971e+00,  1.1696e+00,\n",
       "          1.2513e+00,  3.9385e+00,  1.1892e+00,  5.5995e-01,  1.4068e+00,\n",
       "          1.0918e+00,  3.5005e+00,  1.6766e+00, -8.7261e-01, -7.7876e-01,\n",
       "         -5.5794e-01, -8.1807e-01, -1.6293e+00,  2.4741e-01, -6.0931e-01,\n",
       "         -5.5558e-01, -1.0035e+00, -7.3969e-02, -5.3760e-01, -7.1691e-01,\n",
       "         -4.2199e-02, -9.5032e-01, -1.0792e+00, -6.5887e-01, -6.0594e-01,\n",
       "         -1.2001e+00, -7.5641e-01,  4.2396e-01, -1.0534e+00, -1.1501e-01,\n",
       "          4.0888e-02, -5.3065e-01, -8.6395e-01, -1.6348e-01, -5.9269e-02,\n",
       "          1.9448e-01,  5.7120e-01, -1.0840e+00,  3.7290e-01,  2.1707e-01,\n",
       "         -1.3812e+00, -6.8380e-01,  2.1367e-01, -1.7274e-01, -5.0633e-01,\n",
       "          3.0281e-01,  2.3744e-01, -1.5136e-01, -1.5584e-01, -1.2088e+00,\n",
       "         -9.5901e-01,  1.0417e+00,  4.0830e-01,  2.2005e-01, -4.2032e-01,\n",
       "         -2.9472e-01,  5.0913e-01, -5.4892e-01, -2.6835e-01, -5.6421e-01,\n",
       "         -1.5039e-01, -3.9843e-01,  6.0824e-01,  1.7862e-01, -2.2651e-01,\n",
       "          3.4374e-01,  4.8661e-01,  8.2598e-01, -1.0139e+00,  6.7867e-01,\n",
       "         -6.6808e-01, -5.1679e-01, -3.3567e-01, -2.8918e-01, -1.3328e-01,\n",
       "         -7.2710e-01, -1.0572e+00, -5.3647e-01, -2.1685e-01, -4.9490e-01,\n",
       "         -6.3544e-01,  6.4167e-02, -1.3308e+00, -6.0590e-02,  1.4187e+00]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
