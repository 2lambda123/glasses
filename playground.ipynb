{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from glasses.nn.models.classification import *\n",
    "from glasses.utils.Storage import ForwardModuleStorage\n",
    "from glasses.nn.models.segmentation.unet import *\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder, ResNet, ResNetBottleneckBlock\n",
    "from glasses.nn.models.classification.efficientnet import *\n",
    "from glasses.nn.models.classification import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'resnet-asdsa'\n",
    "\n",
    "name.startswith('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_encoder(model_def, *args, **kwargs):\n",
    "    model = model_def( *args, **kwargs)\n",
    "    encoder = nn.Identity()\n",
    "    if isinstance(model, ResNet):\n",
    "        encoder = WithFeatures(model.encoder, \n",
    "                              stages = [\n",
    "                                  model.encoder.stem[-2], \n",
    "                                  *model.encoder.layers,\n",
    "                              ],\n",
    "                              features_widths = model.encoder.widths[1:]\n",
    "                             )\n",
    "        \n",
    "    elif isinstance(model, EfficientNet):\n",
    "        encoder = WithFeatures(model.encoder, \n",
    "                              stages = [\n",
    "                                  model.encoder.stem[-2], \n",
    "                                  model.encoder.layers[1],\n",
    "                                  model.encoder.layers[2],\n",
    "                                  model.encoder.layers[3],\n",
    "                              ],\n",
    "                              features_widths = [model.encoder.widths[0],\n",
    "                                                 model.encoder.widths[2],\n",
    "                                                 model.encoder.widths[3],\n",
    "                                                 model.encoder.widths[4],\n",
    "                                                ]\n",
    "                             )\n",
    "        \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Got 14 and 112 (The offending index is 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-fb19863a3675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/torcheyes/glasses/nn/models/VisionModule.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, input_shape, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \"\"\"\n\u001b[1;32m     22\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device, dtypes)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     result, params_info = summary_string(\n\u001b[0m\u001b[1;32m     11\u001b[0m         model, input_size, batch_size, device, dtypes)\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary_string\u001b[0;34m(model, input_size, batch_size, device, dtypes)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/torcheyes/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         self.residuals.extend(\n",
      "\u001b[0;32m~/Documents/torcheyes/glasses/nn/models/segmentation/unet/__init__.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Got 14 and 112 (The offending index is 0)"
     ]
    }
   ],
   "source": [
    "m = UNet(encoder = partial(from_encoder, EfficientNet.efficientnet_b2),\n",
    "         decoder = partial(UNetDecoder, widths=[256, 128, 64, 32, 16]),\n",
    ")\n",
    "\n",
    "m.summary((1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (encoder): WithFeatures(\n",
       "    (backbone): EfficientNetEncoder(\n",
       "      (stem): ConvBnAct(\n",
       "        (conv): Conv2dPad(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): Identity()\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): Identity()\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                  (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "                  (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "                  (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n",
       "                  (bn): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(720, 720, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=720, bias=False)\n",
       "                  (bn): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResNetLayer(\n",
       "          (block): Sequential(\n",
       "            (0): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n",
       "                  (bn): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Identity()\n",
       "              )\n",
       "            )\n",
       "            (1): EfficientNetBasicBlock(\n",
       "              (block): Sequential(\n",
       "                (exp): ConvBnAct(\n",
       "                  (conv): Conv2dPad(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (depth): ConvBnAct(\n",
       "                  (conv): Conv2dPad(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n",
       "                  (bn): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (att): ChannelSE(\n",
       "                  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "                  (att): Sequential(\n",
       "                    (conv1): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act1): SiLU(inplace=True)\n",
       "                    (conv2): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n",
       "                    (act2): Sigmoid()\n",
       "                  )\n",
       "                )\n",
       "                (point): Sequential(\n",
       "                  (0): ConvBnAct(\n",
       "                    (conv): Conv2dPad(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  )\n",
       "                )\n",
       "                (drop): Dropout2d(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ConvBnAct(\n",
       "          (conv): Conv2dPad(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UNetDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): UpLayer(\n",
       "        (up): ConvTranspose2d(1408, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (block): UNetBasicBlock(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2dPad(344, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2dPad(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): UpLayer(\n",
       "        (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (block): UNetBasicBlock(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2dPad(176, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2dPad(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): UpLayer(\n",
       "        (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (block): UNetBasicBlock(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2dPad(88, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2dPad(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UpLayer(\n",
       "        (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (block): UNetBasicBlock(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2dPad(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2dPad(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): UpLayer(\n",
       "        (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (block): UNetBasicBlock(\n",
       "          (0): ConvBnAct(\n",
       "            (conv): Conv2dPad(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvBnAct(\n",
       "            (conv): Conv2dPad(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = EfficientNet.efficientnet_b0().encoder\n",
    "\n",
    "\n",
    "encoder = WithFeatures(backbone, \n",
    "                              stages = [\n",
    "                                  backbone.stem[-2], \n",
    "                                  backbone.layers[1],\n",
    "                                  backbone.layers[2],\n",
    "                                  backbone.layers[3],\n",
    "                              ],\n",
    "                              features_widths = [32, 24, 40, 80]\n",
    "                             )\n",
    "\n",
    "\n",
    "m = UNet(encoder = lambda *args, **kwargs: encoder, decoder = partial(UNetDecoder, \n",
    "                                                                      widths=[1280, 256, 128, 64, 32, 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Conv2dPad-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              SiLU-3         [-1, 32, 112, 112]               0\n",
      "          Identity-4         [-1, 32, 112, 112]               0\n",
      "         Conv2dPad-5         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
      "              SiLU-7         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-8             [-1, 32, 1, 1]               0\n",
      "            Conv2d-9              [-1, 8, 1, 1]             264\n",
      "             SiLU-10              [-1, 8, 1, 1]               0\n",
      "           Conv2d-11             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-12             [-1, 32, 1, 1]               0\n",
      "        ChannelSE-13         [-1, 32, 112, 112]               0\n",
      "        Conv2dPad-14         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-15         [-1, 16, 112, 112]              32\n",
      "         Identity-16         [-1, 16, 112, 112]               0\n",
      "EfficientNetBasicBlock-17         [-1, 16, 112, 112]               0\n",
      "      ResNetLayer-18         [-1, 16, 112, 112]               0\n",
      "        Conv2dPad-19         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-20         [-1, 96, 112, 112]             192\n",
      "             SiLU-21         [-1, 96, 112, 112]               0\n",
      "        Conv2dPad-22           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-23           [-1, 96, 56, 56]             192\n",
      "             SiLU-24           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-25             [-1, 96, 1, 1]               0\n",
      "           Conv2d-26              [-1, 4, 1, 1]             388\n",
      "             SiLU-27              [-1, 4, 1, 1]               0\n",
      "           Conv2d-28             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-29             [-1, 96, 1, 1]               0\n",
      "        ChannelSE-30           [-1, 96, 56, 56]               0\n",
      "        Conv2dPad-31           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-32           [-1, 24, 56, 56]              48\n",
      "         Identity-33           [-1, 24, 56, 56]               0\n",
      "EfficientNetBasicBlock-34           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-35          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-36          [-1, 144, 56, 56]             288\n",
      "             SiLU-37          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-38          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-39          [-1, 144, 56, 56]             288\n",
      "             SiLU-40          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-41            [-1, 144, 1, 1]               0\n",
      "           Conv2d-42              [-1, 6, 1, 1]             870\n",
      "             SiLU-43              [-1, 6, 1, 1]               0\n",
      "           Conv2d-44            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-45            [-1, 144, 1, 1]               0\n",
      "        ChannelSE-46          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-47           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-48           [-1, 24, 56, 56]              48\n",
      "        Dropout2d-49           [-1, 24, 56, 56]               0\n",
      "EfficientNetBasicBlock-50           [-1, 24, 56, 56]               0\n",
      "      ResNetLayer-51           [-1, 24, 56, 56]               0\n",
      "        Conv2dPad-52          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-53          [-1, 144, 56, 56]             288\n",
      "             SiLU-54          [-1, 144, 56, 56]               0\n",
      "        Conv2dPad-55          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-56          [-1, 144, 28, 28]             288\n",
      "             SiLU-57          [-1, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-58            [-1, 144, 1, 1]               0\n",
      "           Conv2d-59              [-1, 6, 1, 1]             870\n",
      "             SiLU-60              [-1, 6, 1, 1]               0\n",
      "           Conv2d-61            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-62            [-1, 144, 1, 1]               0\n",
      "        ChannelSE-63          [-1, 144, 28, 28]               0\n",
      "        Conv2dPad-64           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-65           [-1, 40, 28, 28]              80\n",
      "         Identity-66           [-1, 40, 28, 28]               0\n",
      "EfficientNetBasicBlock-67           [-1, 40, 28, 28]               0\n",
      "        Conv2dPad-68          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-69          [-1, 240, 28, 28]             480\n",
      "             SiLU-70          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-71          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-72          [-1, 240, 28, 28]             480\n",
      "             SiLU-73          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-74            [-1, 240, 1, 1]               0\n",
      "           Conv2d-75             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-76             [-1, 10, 1, 1]               0\n",
      "           Conv2d-77            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-78            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-79          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-80           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-81           [-1, 40, 28, 28]              80\n",
      "        Dropout2d-82           [-1, 40, 28, 28]               0\n",
      "EfficientNetBasicBlock-83           [-1, 40, 28, 28]               0\n",
      "      ResNetLayer-84           [-1, 40, 28, 28]               0\n",
      "        Conv2dPad-85          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-86          [-1, 240, 28, 28]             480\n",
      "             SiLU-87          [-1, 240, 28, 28]               0\n",
      "        Conv2dPad-88          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-89          [-1, 240, 14, 14]             480\n",
      "             SiLU-90          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-91            [-1, 240, 1, 1]               0\n",
      "           Conv2d-92             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-93             [-1, 10, 1, 1]               0\n",
      "           Conv2d-94            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-95            [-1, 240, 1, 1]               0\n",
      "        ChannelSE-96          [-1, 240, 14, 14]               0\n",
      "        Conv2dPad-97           [-1, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-98           [-1, 80, 14, 14]             160\n",
      "         Identity-99           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-100           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-101          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-102          [-1, 480, 14, 14]             960\n",
      "            SiLU-103          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-104          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-105          [-1, 480, 14, 14]             960\n",
      "            SiLU-106          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-107            [-1, 480, 1, 1]               0\n",
      "          Conv2d-108             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-109             [-1, 20, 1, 1]               0\n",
      "          Conv2d-110            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-111            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-112          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-113           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-114           [-1, 80, 14, 14]             160\n",
      "       Dropout2d-115           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-116           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-117          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-118          [-1, 480, 14, 14]             960\n",
      "            SiLU-119          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-120          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-121          [-1, 480, 14, 14]             960\n",
      "            SiLU-122          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 480, 1, 1]               0\n",
      "          Conv2d-124             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-125             [-1, 20, 1, 1]               0\n",
      "          Conv2d-126            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-127            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-128          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-129           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-130           [-1, 80, 14, 14]             160\n",
      "       Dropout2d-131           [-1, 80, 14, 14]               0\n",
      "EfficientNetBasicBlock-132           [-1, 80, 14, 14]               0\n",
      "     ResNetLayer-133           [-1, 80, 14, 14]               0\n",
      "       Conv2dPad-134          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-135          [-1, 480, 14, 14]             960\n",
      "            SiLU-136          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-137          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-138          [-1, 480, 14, 14]             960\n",
      "            SiLU-139          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-140            [-1, 480, 1, 1]               0\n",
      "          Conv2d-141             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-142             [-1, 20, 1, 1]               0\n",
      "          Conv2d-143            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-144            [-1, 480, 1, 1]               0\n",
      "       ChannelSE-145          [-1, 480, 14, 14]               0\n",
      "       Conv2dPad-146          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-147          [-1, 112, 14, 14]             224\n",
      "        Identity-148          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-149          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-150          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-151          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-152          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-153          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-154          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-155          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-156            [-1, 672, 1, 1]               0\n",
      "          Conv2d-157             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-158             [-1, 28, 1, 1]               0\n",
      "          Conv2d-159            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-160            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-161          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-162          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-163          [-1, 112, 14, 14]             224\n",
      "       Dropout2d-164          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-165          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-166          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-167          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-168          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-169          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-170          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-171          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-172            [-1, 672, 1, 1]               0\n",
      "          Conv2d-173             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-174             [-1, 28, 1, 1]               0\n",
      "          Conv2d-175            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-176            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-177          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-178          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-179          [-1, 112, 14, 14]             224\n",
      "       Dropout2d-180          [-1, 112, 14, 14]               0\n",
      "EfficientNetBasicBlock-181          [-1, 112, 14, 14]               0\n",
      "     ResNetLayer-182          [-1, 112, 14, 14]               0\n",
      "       Conv2dPad-183          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-184          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-185          [-1, 672, 14, 14]               0\n",
      "       Conv2dPad-186            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-187            [-1, 672, 7, 7]           1,344\n",
      "            SiLU-188            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-189            [-1, 672, 1, 1]               0\n",
      "          Conv2d-190             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-191             [-1, 28, 1, 1]               0\n",
      "          Conv2d-192            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-193            [-1, 672, 1, 1]               0\n",
      "       ChannelSE-194            [-1, 672, 7, 7]               0\n",
      "       Conv2dPad-195            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-196            [-1, 192, 7, 7]             384\n",
      "        Identity-197            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-198            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-199           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-200           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-201           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-202           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-203           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-204           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-205           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-206             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-207             [-1, 48, 1, 1]               0\n",
      "          Conv2d-208           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-209           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-210           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-211            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-212            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-213            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-214            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-215           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-216           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-217           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-218           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-219           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-220           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-221           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-222             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-223             [-1, 48, 1, 1]               0\n",
      "          Conv2d-224           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-225           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-226           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-227            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-228            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-229            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-230            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-231           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-232           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-233           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-234           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-235           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-236           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-237           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-238             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-239             [-1, 48, 1, 1]               0\n",
      "          Conv2d-240           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-241           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-242           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-243            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-244            [-1, 192, 7, 7]             384\n",
      "       Dropout2d-245            [-1, 192, 7, 7]               0\n",
      "EfficientNetBasicBlock-246            [-1, 192, 7, 7]               0\n",
      "     ResNetLayer-247            [-1, 192, 7, 7]               0\n",
      "       Conv2dPad-248           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-249           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-250           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-251           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-252           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-253           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-254           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-255             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-256             [-1, 48, 1, 1]               0\n",
      "          Conv2d-257           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-258           [-1, 1152, 1, 1]               0\n",
      "       ChannelSE-259           [-1, 1152, 7, 7]               0\n",
      "       Conv2dPad-260            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-261            [-1, 320, 7, 7]             640\n",
      "        Identity-262            [-1, 320, 7, 7]               0\n",
      "EfficientNetBasicBlock-263            [-1, 320, 7, 7]               0\n",
      "     ResNetLayer-264            [-1, 320, 7, 7]               0\n",
      "       Conv2dPad-265           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-266           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-267           [-1, 1280, 7, 7]               0\n",
      "EfficientNetEncoder-268           [-1, 1280, 7, 7]               0\n",
      "    WithFeatures-269           [-1, 1280, 7, 7]               0\n",
      " ConvTranspose2d-270         [-1, 1280, 14, 14]       6,554,880\n",
      "       Conv2dPad-271         [-1, 1280, 14, 14]      15,667,200\n",
      "     BatchNorm2d-272         [-1, 1280, 14, 14]           2,560\n",
      "            ReLU-273         [-1, 1280, 14, 14]               0\n",
      "       Conv2dPad-274         [-1, 1280, 14, 14]      14,745,600\n",
      "     BatchNorm2d-275         [-1, 1280, 14, 14]           2,560\n",
      "            ReLU-276         [-1, 1280, 14, 14]               0\n",
      "         UpLayer-277         [-1, 1280, 14, 14]               0\n",
      " ConvTranspose2d-278          [-1, 256, 28, 28]       1,310,976\n",
      "       Conv2dPad-279          [-1, 256, 28, 28]         681,984\n",
      "     BatchNorm2d-280          [-1, 256, 28, 28]             512\n",
      "            ReLU-281          [-1, 256, 28, 28]               0\n",
      "       Conv2dPad-282          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-283          [-1, 256, 28, 28]             512\n",
      "            ReLU-284          [-1, 256, 28, 28]               0\n",
      "         UpLayer-285          [-1, 256, 28, 28]               0\n",
      " ConvTranspose2d-286          [-1, 128, 56, 56]         131,200\n",
      "       Conv2dPad-287          [-1, 128, 56, 56]         175,104\n",
      "     BatchNorm2d-288          [-1, 128, 56, 56]             256\n",
      "            ReLU-289          [-1, 128, 56, 56]               0\n",
      "       Conv2dPad-290          [-1, 128, 56, 56]         147,456\n",
      "     BatchNorm2d-291          [-1, 128, 56, 56]             256\n",
      "            ReLU-292          [-1, 128, 56, 56]               0\n",
      "         UpLayer-293          [-1, 128, 56, 56]               0\n",
      " ConvTranspose2d-294         [-1, 64, 112, 112]          32,832\n",
      "       Conv2dPad-295         [-1, 64, 112, 112]          55,296\n",
      "     BatchNorm2d-296         [-1, 64, 112, 112]             128\n",
      "            ReLU-297         [-1, 64, 112, 112]               0\n",
      "       Conv2dPad-298         [-1, 64, 112, 112]          36,864\n",
      "     BatchNorm2d-299         [-1, 64, 112, 112]             128\n",
      "            ReLU-300         [-1, 64, 112, 112]               0\n",
      "         UpLayer-301         [-1, 64, 112, 112]               0\n",
      " ConvTranspose2d-302         [-1, 32, 224, 224]           8,224\n",
      "       Conv2dPad-303         [-1, 32, 224, 224]           9,216\n",
      "     BatchNorm2d-304         [-1, 32, 224, 224]              64\n",
      "            ReLU-305         [-1, 32, 224, 224]               0\n",
      "       Conv2dPad-306         [-1, 32, 224, 224]           9,216\n",
      "     BatchNorm2d-307         [-1, 32, 224, 224]              64\n",
      "            ReLU-308         [-1, 32, 224, 224]               0\n",
      "         UpLayer-309         [-1, 32, 224, 224]               0\n",
      " ConvTranspose2d-310         [-1, 16, 448, 448]           2,064\n",
      "       Conv2dPad-311         [-1, 16, 448, 448]           2,304\n",
      "     BatchNorm2d-312         [-1, 16, 448, 448]              32\n",
      "            ReLU-313         [-1, 16, 448, 448]               0\n",
      "       Conv2dPad-314         [-1, 16, 448, 448]           2,304\n",
      "     BatchNorm2d-315         [-1, 16, 448, 448]              32\n",
      "            ReLU-316         [-1, 16, 448, 448]               0\n",
      "         UpLayer-317         [-1, 16, 448, 448]               0\n",
      "     UNetDecoder-318         [-1, 16, 448, 448]               0\n",
      "          Conv2d-319          [-1, 2, 448, 448]              34\n",
      "            UNet-320          [-1, 2, 448, 448]               0\n",
      "================================================================\n",
      "Total params: 44,177,230\n",
      "Trainable params: 44,177,230\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 608.98\n",
      "Params size (MB): 168.52\n",
      "Estimated Total Size (MB): 778.08\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(44177230), tensor(44177230), tensor(168.5228), tensor(778.0754))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.summary((3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.efficientnet import *\n",
    "import timm\n",
    "\n",
    "from transfer_weights import clone_model\n",
    "from benchmark import benchmark\n",
    "\n",
    "src = timm.create_model('tf_efficientnet_lite1', pretrained='True')\n",
    "dst = EfficientNetLite.efficientnet_lite1(mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = clone_model(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# transform = dst.configs['efficientnet_lite1'].transform\n",
    "\n",
    "# benchmark(dst.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# benchmark(src.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = timm.create_model('efficientnet_b0', pretrained='True')\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
