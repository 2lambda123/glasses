{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import segmentation_models_pytorch as smp\n",
    "# model = smp.FPN(\n",
    "#     encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "#     in_channels=1,                  # model input channels (1 for grayscale images, 3 for RGB, etc.)\n",
    "#     classes=3,                      # model output channels (number of classes in your dataset)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glasses.nn.models.segmentation.fpn import *\n",
    "from glasses.nn.models.segmentation.unet import UNetEncoder\n",
    "from glasses.nn.models import ResNet\n",
    "from functools import partial\n",
    "import torch\n",
    "from glasses.nn.models.AutoModel import AutoModel\n",
    "\n",
    "fpn = FPN()\n",
    "\n",
    "# fpn.summary(input_shape=(1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 128, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "pred = fpn(torch.randn(2,1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 224, 224])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 448, 448])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.nn.models.segmentation.unet import UNet, UNetDecoder\n",
    "\n",
    "unet = UNet()\n",
    "unet(torch.randn(2,1,224,224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet.resnet18().encoder.features_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.cat(features, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(features, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(torch.vstack(features), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.shape for f in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.AutoModel import AutoModel\n",
    "from glasses.nn.models.AutoConfig import AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_name('resnet18')\n",
    "# notify to the model we want to have the features\n",
    "model.encoder.features\n",
    "model(torch.rand((1,3,224,224)))\n",
    "# get the features :)\n",
    "features = model.encoder.features\n",
    "[print(f.shape) for f in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.from_name('unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glasses.nn.models.classification import *\n",
    "from glasses.utils.Storage import ForwardModuleStorage\n",
    "from glasses.nn.models.segmentation.unet import *\n",
    "from glasses.nn.models.classification.resnet import ResNetEncoder, ResNet, ResNetBottleneckBlock\n",
    "from glasses.nn.models.classification.efficientnet import *\n",
    "from glasses.nn.models.classification import *\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet.from_encoder(lambda *args, **kwargs: ResNet.resnet18(*args, **kwargs))\n",
    "\n",
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unet = UNet.from_encoder(partial(AutoModel.from_name, 'resnet18'))\n",
    "model.summary(input_shape=(1,384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from glasses.nn.models import *\n",
    "timm.create_model('seresnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEResNet.cse_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = EfficientNet.efficientnet_b0().encoder\n",
    "x = torch.randn((1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glasses.nn.models.classification.efficientnet import *\n",
    "import timm\n",
    "\n",
    "from transfer_weights import clone_model\n",
    "from benchmark import benchmark\n",
    "\n",
    "src = timm.create_model('tf_efficientnet_lite1', pretrained='True')\n",
    "dst = EfficientNetLite.efficientnet_lite1(mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_encoder(model_def, *args, **kwargs):\n",
    "    model = model_def( *args, **kwargs)\n",
    "    encoder = nn.Identity()\n",
    "    if isinstance(model, ResNet):\n",
    "        encoder = WithFeatures(model.encoder, \n",
    "                              stages = [\n",
    "                                  model.encoder.stem[-2], \n",
    "                                  *model.encoder.layers,\n",
    "                              ],\n",
    "                              features_widths = model.encoder.widths[1:]\n",
    "                             )\n",
    "        \n",
    "    elif isinstance(model, EfficientNet):\n",
    "        encoder = WithFeatures(model.encoder, \n",
    "                              stages = [\n",
    "                                  model.encoder.stem[-2], \n",
    "                                  model.encoder.layers[1],\n",
    "                                  model.encoder.layers[2],\n",
    "                                  model.encoder.layers[3],\n",
    "                              ],\n",
    "                              features_widths = [model.encoder.widths[0],\n",
    "                                                 model.encoder.widths[2],\n",
    "                                                 model.encoder.widths[3],\n",
    "                                                 model.encoder.widths[4],\n",
    "                                                ]\n",
    "                             )\n",
    "        \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = ResNet.resnet18().encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.features_widths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc.stages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.features\n",
    "\n",
    "enc(x)\n",
    "\n",
    "enc.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = EfficientNet.efficientnet_b0().encoder\n",
    "\n",
    "\n",
    "encoder = WithFeatures(backbone, \n",
    "                              stages = [\n",
    "                                  backbone.stem[-2], \n",
    "                                  backbone.layers[1],\n",
    "                                  backbone.layers[2],\n",
    "                                  backbone.layers[3],\n",
    "                              ],\n",
    "                              features_widths = [32, 24, 40, 80]\n",
    "                             )\n",
    "\n",
    "\n",
    "m = UNet(encoder = lambda *args, **kwargs: encoder, decoder = partial(UNetDecoder, \n",
    "                                                                      widths=[1280, 256, 128, 64, 32, 16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'resnet-asdsa'\n",
    "\n",
    "name.startswith('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.summary((3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = clone_model(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# transform = dst.configs['efficientnet_lite1'].transform\n",
    "\n",
    "# benchmark(dst.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# benchmark(src.cuda(), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = timm.create_model('efficientnet_b0', pretrained='True')\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
