{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preambula\n",
    "To get started you need to install glasses, this can be done through `pip`\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/FrancescoSaverioZuppichini/glasses\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Train a deep convolutional neural network may take a lot of time, **transfer learning**, as the name suggests, use models already trained on a huge image dataset, such as ImageNet, to speed up the learning procedure. \n",
    "\n",
    "Even if your dataset may be different than ImageNet, the pre-trained models have learned useful weights that can be easily adapt to your new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Model\n",
    "\n",
    "You can use `AutoModel` and `AutoConfig` to load your model and your preprocessing function. In this tutorial, we are going to use `resnet34`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded resnet34 pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "from glasses.models import AutoModel, AutoConfig\n",
    "\n",
    "resnet34 = AutoModel.from_pretrained('resnet34') \n",
    "cfg = AutoConfig.from_name('resnet34')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call `.summary()` to see your models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AutoConfig` returns the correct configuration for a specific model. This is crucial because you need to properly preprocess your input in the same way it was done when the model was originally trained. `cfg` returns a `Config` object that contains the correct PyTorch transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = cfg.transform\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of available models can be obtained using `AutoModel.models()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze model layers and replace the classification head\n",
    "\n",
    "Cool, we have our model. Now we need to **freeze** the convolution layers and change the classification head. In glasses, each classification model is composed by a `Encoder` (where the convs are) and a `Head` (usually a linear layer) that performs the final classification. Each `Encoder` has the `.widths` field that tells the number of output features at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 128, 256, 512]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glasses.models.classification.resnet import ResNetHead\n",
    "\n",
    "resnet34.freeze(who=resnet34.encoder)\n",
    "# head will need to know how many features we are passing into\n",
    "resnet34.head = ResNetHead(in_features=resnet34.encoder.widths[-1], n_classes=2)\n",
    "# just to show you\n",
    "resnet34.encoder.widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no grad in the encoder\n",
    "for param in resnet34.encoder.parameters():\n",
    "    assert not param.requires_grad\n",
    "# grad in the head\n",
    "for param in resnet34.head.parameters():\n",
    "    assert param.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your model is ready to train it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
